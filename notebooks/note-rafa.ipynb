{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997cd09a",
   "metadata": {},
   "source": [
    "#Base Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6994422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of imports\n",
    "\n",
    "#basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#specific imports\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#Sklearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose    import make_column_transformer, make_column_selector\n",
    "\n",
    "from sklearn.metrics    import mean_squared_error,mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f3b9ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Basis</th>\n",
       "      <th>Upper</th>\n",
       "      <th>Lower</th>\n",
       "      <th>Up Trend</th>\n",
       "      <th>Down Trend</th>\n",
       "      <th>KAMA</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Bollinger Bands %b</th>\n",
       "      <th>Bollinger BandWidth</th>\n",
       "      <th>Highest Expansion</th>\n",
       "      <th>Lowest Contraction</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/11/22 0:00</td>\n",
       "      <td>1801.23</td>\n",
       "      <td>1802.85</td>\n",
       "      <td>1800.03</td>\n",
       "      <td>1801.18</td>\n",
       "      <td>1796.565</td>\n",
       "      <td>1802.85</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1790.975815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1795.256156</td>\n",
       "      <td>65.669045</td>\n",
       "      <td>0.831694</td>\n",
       "      <td>0.803134</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/11/22 1:00</td>\n",
       "      <td>1801.16</td>\n",
       "      <td>1804.61</td>\n",
       "      <td>1801.15</td>\n",
       "      <td>1802.70</td>\n",
       "      <td>1797.445</td>\n",
       "      <td>1804.61</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1792.424234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1795.536505</td>\n",
       "      <td>69.806836</td>\n",
       "      <td>0.888896</td>\n",
       "      <td>0.826182</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/11/22 2:00</td>\n",
       "      <td>1802.68</td>\n",
       "      <td>1805.91</td>\n",
       "      <td>1802.00</td>\n",
       "      <td>1804.85</td>\n",
       "      <td>1798.095</td>\n",
       "      <td>1805.91</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1793.371810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1795.896520</td>\n",
       "      <td>74.665739</td>\n",
       "      <td>0.963492</td>\n",
       "      <td>0.876434</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/11/22 3:00</td>\n",
       "      <td>1804.83</td>\n",
       "      <td>1806.31</td>\n",
       "      <td>1804.21</td>\n",
       "      <td>1805.18</td>\n",
       "      <td>1798.295</td>\n",
       "      <td>1806.31</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1795.105129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1796.250762</td>\n",
       "      <td>75.350694</td>\n",
       "      <td>0.925586</td>\n",
       "      <td>0.917716</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/11/22 4:00</td>\n",
       "      <td>1805.18</td>\n",
       "      <td>1807.73</td>\n",
       "      <td>1804.99</td>\n",
       "      <td>1805.91</td>\n",
       "      <td>1799.005</td>\n",
       "      <td>1807.73</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1796.398616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1796.635508</td>\n",
       "      <td>76.904655</td>\n",
       "      <td>0.915073</td>\n",
       "      <td>0.952947</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/11/22 5:00</td>\n",
       "      <td>1805.88</td>\n",
       "      <td>1806.73</td>\n",
       "      <td>1805.52</td>\n",
       "      <td>1806.72</td>\n",
       "      <td>1799.005</td>\n",
       "      <td>1807.73</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1796.796755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1797.136618</td>\n",
       "      <td>78.589560</td>\n",
       "      <td>0.909138</td>\n",
       "      <td>0.987403</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/11/22 6:00</td>\n",
       "      <td>1806.71</td>\n",
       "      <td>1808.63</td>\n",
       "      <td>1805.65</td>\n",
       "      <td>1808.41</td>\n",
       "      <td>1799.455</td>\n",
       "      <td>1808.63</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1797.850579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1797.752024</td>\n",
       "      <td>81.719853</td>\n",
       "      <td>0.936550</td>\n",
       "      <td>1.063483</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/11/22 7:00</td>\n",
       "      <td>1808.37</td>\n",
       "      <td>1809.79</td>\n",
       "      <td>1807.01</td>\n",
       "      <td>1808.22</td>\n",
       "      <td>1800.035</td>\n",
       "      <td>1809.79</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1799.205521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1798.448651</td>\n",
       "      <td>80.236144</td>\n",
       "      <td>0.876940</td>\n",
       "      <td>1.118710</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/11/22 8:00</td>\n",
       "      <td>1808.22</td>\n",
       "      <td>1809.74</td>\n",
       "      <td>1807.57</td>\n",
       "      <td>1809.18</td>\n",
       "      <td>1800.035</td>\n",
       "      <td>1809.79</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1799.728969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1799.305851</td>\n",
       "      <td>82.085020</td>\n",
       "      <td>0.876583</td>\n",
       "      <td>1.190612</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/11/22 9:00</td>\n",
       "      <td>1809.11</td>\n",
       "      <td>1810.16</td>\n",
       "      <td>1808.21</td>\n",
       "      <td>1808.82</td>\n",
       "      <td>1800.220</td>\n",
       "      <td>1810.16</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1800.566572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1799.996176</td>\n",
       "      <td>78.968473</td>\n",
       "      <td>0.825063</td>\n",
       "      <td>1.246739</td>\n",
       "      <td>2.495776</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           time     open     high      low    close     Basis    Upper  \\\n",
       "0  1/11/22 0:00  1801.23  1802.85  1800.03  1801.18  1796.565  1802.85   \n",
       "1  1/11/22 1:00  1801.16  1804.61  1801.15  1802.70  1797.445  1804.61   \n",
       "2  1/11/22 2:00  1802.68  1805.91  1802.00  1804.85  1798.095  1805.91   \n",
       "3  1/11/22 3:00  1804.83  1806.31  1804.21  1805.18  1798.295  1806.31   \n",
       "4  1/11/22 4:00  1805.18  1807.73  1804.99  1805.91  1799.005  1807.73   \n",
       "5  1/11/22 5:00  1805.88  1806.73  1805.52  1806.72  1799.005  1807.73   \n",
       "6  1/11/22 6:00  1806.71  1808.63  1805.65  1808.41  1799.455  1808.63   \n",
       "7  1/11/22 7:00  1808.37  1809.79  1807.01  1808.22  1800.035  1809.79   \n",
       "8  1/11/22 8:00  1808.22  1809.74  1807.57  1809.18  1800.035  1809.79   \n",
       "9  1/11/22 9:00  1809.11  1810.16  1808.21  1808.82  1800.220  1810.16   \n",
       "\n",
       "     Lower     Up Trend  Down Trend         KAMA        RSI  \\\n",
       "0  1790.28  1790.975815         NaN  1795.256156  65.669045   \n",
       "1  1790.28  1792.424234         NaN  1795.536505  69.806836   \n",
       "2  1790.28  1793.371810         NaN  1795.896520  74.665739   \n",
       "3  1790.28  1795.105129         NaN  1796.250762  75.350694   \n",
       "4  1790.28  1796.398616         NaN  1796.635508  76.904655   \n",
       "5  1790.28  1796.796755         NaN  1797.136618  78.589560   \n",
       "6  1790.28  1797.850579         NaN  1797.752024  81.719853   \n",
       "7  1790.28  1799.205521         NaN  1798.448651  80.236144   \n",
       "8  1790.28  1799.728969         NaN  1799.305851  82.085020   \n",
       "9  1790.28  1800.566572         NaN  1799.996176  78.968473   \n",
       "\n",
       "   Bollinger Bands %b  Bollinger BandWidth  Highest Expansion  \\\n",
       "0            0.831694             0.803134           2.519134   \n",
       "1            0.888896             0.826182           2.519134   \n",
       "2            0.963492             0.876434           2.519134   \n",
       "3            0.925586             0.917716           2.519134   \n",
       "4            0.915073             0.952947           2.519134   \n",
       "5            0.909138             0.987403           2.519134   \n",
       "6            0.936550             1.063483           2.519134   \n",
       "7            0.876940             1.118710           2.519134   \n",
       "8            0.876583             1.190612           2.519134   \n",
       "9            0.825063             1.246739           2.495776   \n",
       "\n",
       "   Lowest Contraction  Unnamed: 16  \n",
       "0            0.332677          NaN  \n",
       "1            0.332677          NaN  \n",
       "2            0.332677          NaN  \n",
       "3            0.332677          NaN  \n",
       "4            0.332677          NaN  \n",
       "5            0.332677          NaN  \n",
       "6            0.332677          NaN  \n",
       "7            0.332677          NaN  \n",
       "8            0.332677          NaN  \n",
       "9            0.332677          NaN  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading data\n",
    "\n",
    "data = pd.read_csv('/Users/rafael.hayashi/code/rafaeltshayashi/Forecasting-Gold-Price/raw_data/Extract_TimeFrame_60_clean.csv', sep=';')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8022351e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visual check\n",
    "\n",
    "data['close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "51f25a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/0c80h97d4ksflxwnpnhp9g2m0000gn/T/ipykernel_77034/1818197618.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  X['time'] = pd.to_datetime(X['time'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((23111, 14), (23111,))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Features and target\n",
    "X = data.drop(columns=['close','Up Trend','Down Trend','Unnamed: 16'])\n",
    "X['time'] = pd.to_datetime(X['time'])\n",
    "X['unix_timestamp'] = X['time'].apply(lambda x: x.timestamp())\n",
    "X = X[1:]\n",
    "y = data['close'].shift(1).dropna()\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5a481197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64           13\n",
       "datetime64[ns]     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data check\n",
    "X.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d65546a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d76444d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1801.18\n",
       "2    1802.70\n",
       "3    1804.85\n",
       "4    1805.18\n",
       "5    1805.91\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d9f22575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>Basis</th>\n",
       "      <th>Upper</th>\n",
       "      <th>Lower</th>\n",
       "      <th>KAMA</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Bollinger Bands %b</th>\n",
       "      <th>Bollinger BandWidth</th>\n",
       "      <th>Highest Expansion</th>\n",
       "      <th>Lowest Contraction</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-11 01:00:00</td>\n",
       "      <td>1801.16</td>\n",
       "      <td>1804.61</td>\n",
       "      <td>1801.15</td>\n",
       "      <td>1797.445</td>\n",
       "      <td>1804.61</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1795.536505</td>\n",
       "      <td>69.806836</td>\n",
       "      <td>0.888896</td>\n",
       "      <td>0.826182</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>1.641863e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-11 02:00:00</td>\n",
       "      <td>1802.68</td>\n",
       "      <td>1805.91</td>\n",
       "      <td>1802.00</td>\n",
       "      <td>1798.095</td>\n",
       "      <td>1805.91</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1795.896520</td>\n",
       "      <td>74.665739</td>\n",
       "      <td>0.963492</td>\n",
       "      <td>0.876434</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>1.641866e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-11 03:00:00</td>\n",
       "      <td>1804.83</td>\n",
       "      <td>1806.31</td>\n",
       "      <td>1804.21</td>\n",
       "      <td>1798.295</td>\n",
       "      <td>1806.31</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1796.250762</td>\n",
       "      <td>75.350694</td>\n",
       "      <td>0.925586</td>\n",
       "      <td>0.917716</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>1.641870e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-11 04:00:00</td>\n",
       "      <td>1805.18</td>\n",
       "      <td>1807.73</td>\n",
       "      <td>1804.99</td>\n",
       "      <td>1799.005</td>\n",
       "      <td>1807.73</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1796.635508</td>\n",
       "      <td>76.904655</td>\n",
       "      <td>0.915073</td>\n",
       "      <td>0.952947</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>1.641874e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-01-11 05:00:00</td>\n",
       "      <td>1805.88</td>\n",
       "      <td>1806.73</td>\n",
       "      <td>1805.52</td>\n",
       "      <td>1799.005</td>\n",
       "      <td>1807.73</td>\n",
       "      <td>1790.28</td>\n",
       "      <td>1797.136618</td>\n",
       "      <td>78.589560</td>\n",
       "      <td>0.909138</td>\n",
       "      <td>0.987403</td>\n",
       "      <td>2.519134</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>1.641877e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time     open     high      low     Basis    Upper    Lower  \\\n",
       "1 2022-01-11 01:00:00  1801.16  1804.61  1801.15  1797.445  1804.61  1790.28   \n",
       "2 2022-01-11 02:00:00  1802.68  1805.91  1802.00  1798.095  1805.91  1790.28   \n",
       "3 2022-01-11 03:00:00  1804.83  1806.31  1804.21  1798.295  1806.31  1790.28   \n",
       "4 2022-01-11 04:00:00  1805.18  1807.73  1804.99  1799.005  1807.73  1790.28   \n",
       "5 2022-01-11 05:00:00  1805.88  1806.73  1805.52  1799.005  1807.73  1790.28   \n",
       "\n",
       "          KAMA        RSI  Bollinger Bands %b  Bollinger BandWidth  \\\n",
       "1  1795.536505  69.806836            0.888896             0.826182   \n",
       "2  1795.896520  74.665739            0.963492             0.876434   \n",
       "3  1796.250762  75.350694            0.925586             0.917716   \n",
       "4  1796.635508  76.904655            0.915073             0.952947   \n",
       "5  1797.136618  78.589560            0.909138             0.987403   \n",
       "\n",
       "   Highest Expansion  Lowest Contraction  unix_timestamp  \n",
       "1           2.519134            0.332677    1.641863e+09  \n",
       "2           2.519134            0.332677    1.641866e+09  \n",
       "3           2.519134            0.332677    1.641870e+09  \n",
       "4           2.519134            0.332677    1.641874e+09  \n",
       "5           2.519134            0.332677    1.641877e+09  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3d2ef258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer()),\n",
       "                                                 (&#x27;robustscaler&#x27;,\n",
       "                                                  RobustScaler())]),\n",
       "                                 [&#x27;open&#x27;, &#x27;high&#x27;, &#x27;low&#x27;, &#x27;Basis&#x27;, &#x27;Upper&#x27;,\n",
       "                                  &#x27;Lower&#x27;, &#x27;KAMA&#x27;, &#x27;RSI&#x27;, &#x27;Bollinger Bands %b&#x27;,\n",
       "                                  &#x27;Bollinger BandWidth&#x27;, &#x27;Highest Expansion&#x27;,\n",
       "                                  &#x27;Lowest Contraction&#x27;, &#x27;unix_timestamp&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(transformers=[(&#x27;pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer()),\n",
       "                                                 (&#x27;robustscaler&#x27;,\n",
       "                                                  RobustScaler())]),\n",
       "                                 [&#x27;open&#x27;, &#x27;high&#x27;, &#x27;low&#x27;, &#x27;Basis&#x27;, &#x27;Upper&#x27;,\n",
       "                                  &#x27;Lower&#x27;, &#x27;KAMA&#x27;, &#x27;RSI&#x27;, &#x27;Bollinger Bands %b&#x27;,\n",
       "                                  &#x27;Bollinger BandWidth&#x27;, &#x27;Highest Expansion&#x27;,\n",
       "                                  &#x27;Lowest Contraction&#x27;, &#x27;unix_timestamp&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>pipeline</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;open&#x27;, &#x27;high&#x27;, &#x27;low&#x27;, &#x27;Basis&#x27;, &#x27;Upper&#x27;, &#x27;Lower&#x27;, &#x27;KAMA&#x27;, &#x27;RSI&#x27;, &#x27;Bollinger Bands %b&#x27;, &#x27;Bollinger BandWidth&#x27;, &#x27;Highest Expansion&#x27;, &#x27;Lowest Contraction&#x27;, &#x27;unix_timestamp&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>RobustScaler</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.RobustScaler.html\">?<span>Documentation for RobustScaler</span></a></div></label><div class=\"sk-toggleable__content \"><pre>RobustScaler()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('pipeline',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer()),\n",
       "                                                 ('robustscaler',\n",
       "                                                  RobustScaler())]),\n",
       "                                 ['open', 'high', 'low', 'Basis', 'Upper',\n",
       "                                  'Lower', 'KAMA', 'RSI', 'Bollinger Bands %b',\n",
       "                                  'Bollinger BandWidth', 'Highest Expansion',\n",
       "                                  'Lowest Contraction', 'unix_timestamp'])])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing\n",
    "\n",
    "preproc_numerical_baseline = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    RobustScaler()\n",
    ")\n",
    "\n",
    "preproc_baseline = make_column_transformer(\n",
    "    (preproc_numerical_baseline, ['open', 'high', 'low', 'Basis', 'Upper', 'Lower', 'KAMA', 'RSI', 'Bollinger Bands %b', 'Bollinger BandWidth', 'Highest Expansion', 'Lowest Contraction','unix_timestamp']),\n",
    ")\n",
    "\n",
    "preproc_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cfe786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "662a7a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create eval test just for early-stopping purposes (XGBOOST and Deep Learning)\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_eval = X[:train_size], X[train_size:]\n",
    "y_train, y_eval = y[:train_size], y[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1be59b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess eval data\n",
    "preproc_baseline.fit(X_train, y_train)\n",
    "X_train_preproc = preproc_baseline.transform(X_train)\n",
    "X_eval_preproc = preproc_baseline.transform(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e9f39d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33579243, -0.33258422, -0.33195834, ...,  0.04680314,\n",
       "        -0.23891313, -0.99375658],\n",
       "       [-0.33266236, -0.32991006, -0.33020522, ...,  0.04680314,\n",
       "        -0.23891313, -0.99368398],\n",
       "       [-0.32823496, -0.32908723, -0.32564711, ...,  0.04680314,\n",
       "        -0.23891313, -0.99361138],\n",
       "       ...,\n",
       "       [ 1.89627532,  1.90462477,  1.89551408, ..., -0.27082227,\n",
       "         1.25863057,  0.99869324],\n",
       "       [ 1.90451234,  1.90513903,  1.86806229, ..., -0.27082227,\n",
       "         1.25863057,  0.99876584],\n",
       "       [ 1.87004041,  1.88487707,  1.87367227, ..., -0.27082227,\n",
       "         1.25863057,  0.99883843]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "67b9b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model_xgb = XGBRegressor(max_depth=2,\n",
    "                         n_estimators=500,\n",
    "                         learning_rate=0.3\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "35d34379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1651.26\n",
      "MAE: 1651.65\n",
      "MAE: 1651.17\n",
      "MAE: 1651.46\n",
      "MAE: 1651.50\n",
      "MAE: 1650.76\n",
      "MAE: 1651.66\n",
      "MAE: 1651.40\n",
      "MAE: 1651.19\n",
      "MAE: 1651.50\n",
      "MAE: 1651.84\n",
      "MAE: 1651.06\n",
      "MAE: 1651.47\n",
      "MAE: 1650.94\n",
      "MAE: 1651.28\n",
      "MAE: 1651.02\n",
      "MAE: 1651.25\n",
      "MAE: 1651.17\n",
      "MAE: 1651.49\n",
      "MAE: 1646.88\n",
      "MAE: 1644.33\n",
      "MAE: 1643.31\n",
      "MAE: 1642.87\n",
      "MAE: 1642.70\n",
      "MAE: 1642.96\n",
      "MAE: 1642.80\n",
      "MAE: 1642.25\n",
      "MAE: 1642.61\n",
      "MAE: 1642.84\n",
      "MAE: 1642.13\n",
      "MAE: 1642.24\n",
      "MAE: 1642.96\n",
      "MAE: 1642.94\n",
      "MAE: 1642.74\n",
      "MAE: 1642.91\n",
      "MAE: 1642.45\n",
      "MAE: 1643.01\n",
      "MAE: 1643.48\n",
      "MAE: 1637.23\n",
      "MAE: 1635.61\n",
      "MAE: 1635.72\n",
      "MAE: 1635.55\n",
      "MAE: 1632.10\n",
      "MAE: 1632.15\n",
      "MAE: 1631.43\n",
      "MAE: 1630.79\n",
      "MAE: 1631.68\n",
      "MAE: 1631.05\n",
      "MAE: 1631.09\n",
      "MAE: 1627.32\n",
      "MAE: 1625.47\n",
      "MAE: 1625.65\n",
      "MAE: 1625.62\n",
      "MAE: 1624.63\n",
      "MAE: 1624.85\n",
      "MAE: 1624.57\n",
      "MAE: 1626.92\n",
      "MAE: 1625.22\n",
      "MAE: 1625.46\n",
      "MAE: 1624.66\n",
      "MAE: 1624.86\n",
      "MAE: 1624.79\n",
      "MAE: 1625.52\n",
      "MAE: 1623.58\n",
      "MAE: 1623.47\n",
      "MAE: 1624.00\n",
      "MAE: 1624.30\n",
      "MAE: 1623.01\n",
      "MAE: 1623.42\n",
      "MAE: 1624.23\n",
      "MAE: 1624.82\n",
      "MAE: 1624.62\n",
      "MAE: 1624.44\n",
      "MAE: 1624.60\n",
      "MAE: 1624.54\n",
      "MAE: 1625.37\n",
      "MAE: 1625.05\n",
      "MAE: 1625.00\n",
      "MAE: 1624.18\n",
      "MAE: 1624.37\n",
      "MAE: 1624.62\n",
      "MAE: 1625.05\n",
      "MAE: 1624.60\n",
      "MAE: 1625.63\n",
      "MAE: 1624.23\n",
      "MAE: 1626.07\n",
      "MAE: 1623.46\n",
      "MAE: 1625.18\n",
      "MAE: 1623.76\n",
      "MAE: 1624.50\n",
      "MAE: 1625.07\n",
      "MAE: 1624.83\n",
      "MAE: 1624.54\n",
      "MAE: 1624.62\n",
      "MAE: 1623.99\n",
      "MAE: 1625.15\n",
      "MAE: 1624.92\n",
      "MAE: 1625.48\n",
      "MAE: 1624.94\n",
      "MAE: 1625.14\n",
      "MAE: 1625.32\n",
      "MAE: 1617.54\n",
      "MAE: 1615.30\n",
      "MAE: 1616.69\n",
      "MAE: 1615.01\n",
      "MAE: 1616.04\n",
      "MAE: 1607.26\n",
      "MAE: 1609.47\n",
      "MAE: 1608.03\n",
      "MAE: 1607.76\n",
      "MAE: 1606.96\n",
      "MAE: 1605.74\n",
      "MAE: 1604.29\n",
      "MAE: 1603.43\n",
      "MAE: 1604.97\n",
      "MAE: 1603.79\n",
      "MAE: 1603.56\n",
      "MAE: 1603.88\n",
      "MAE: 1603.49\n",
      "MAE: 1603.29\n",
      "MAE: 1602.91\n",
      "MAE: 1603.74\n",
      "MAE: 1604.10\n",
      "MAE: 1604.04\n",
      "MAE: 1605.11\n",
      "MAE: 1603.23\n",
      "MAE: 1602.91\n",
      "MAE: 1604.08\n",
      "MAE: 1603.11\n",
      "MAE: 1603.05\n",
      "MAE: 1603.41\n",
      "MAE: 1603.38\n",
      "MAE: 1604.05\n",
      "MAE: 1603.63\n",
      "MAE: 1603.20\n",
      "MAE: 1603.38\n",
      "MAE: 1603.64\n",
      "MAE: 1604.40\n",
      "MAE: 1598.56\n",
      "MAE: 1599.02\n",
      "MAE: 1599.28\n",
      "MAE: 1599.10\n",
      "MAE: 1598.26\n",
      "MAE: 1598.84\n",
      "MAE: 1598.95\n",
      "MAE: 1599.33\n",
      "MAE: 1598.36\n",
      "MAE: 1598.80\n",
      "MAE: 1599.58\n",
      "MAE: 1599.13\n",
      "MAE: 1599.37\n",
      "MAE: 1598.93\n",
      "MAE: 1598.33\n",
      "MAE: 1598.13\n",
      "MAE: 1598.55\n",
      "MAE: 1598.53\n",
      "MAE: 1598.46\n",
      "MAE: 1598.36\n",
      "MAE: 1598.14\n",
      "MAE: 1594.65\n",
      "MAE: 1594.69\n",
      "MAE: 1594.39\n",
      "MAE: 1593.33\n",
      "MAE: 1593.70\n",
      "MAE: 1593.29\n",
      "MAE: 1593.09\n",
      "MAE: 1592.51\n",
      "MAE: 1593.45\n",
      "MAE: 1594.16\n",
      "MAE: 1595.74\n",
      "MAE: 1594.49\n",
      "MAE: 1594.18\n",
      "MAE: 1595.06\n",
      "MAE: 1593.98\n",
      "MAE: 1593.72\n",
      "MAE: 1595.70\n",
      "MAE: 1596.34\n",
      "MAE: 1595.38\n",
      "MAE: 1596.38\n",
      "MAE: 1594.66\n",
      "MAE: 1595.95\n",
      "MAE: 1593.67\n",
      "MAE: 1596.09\n",
      "MAE: 1595.38\n",
      "MAE: 1594.34\n",
      "MAE: 1596.15\n",
      "MAE: 1593.96\n",
      "MAE: 1595.78\n",
      "MAE: 1594.40\n",
      "MAE: 1594.41\n",
      "MAE: 1595.08\n",
      "MAE: 1596.98\n",
      "MAE: 1595.31\n",
      "MAE: 1596.45\n",
      "MAE: 1596.09\n",
      "MAE: 1595.83\n",
      "MAE: 1596.87\n",
      "MAE: 1596.45\n",
      "MAE: 1596.71\n",
      "MAE: 1593.27\n",
      "MAE: 1593.74\n",
      "MAE: 1595.23\n",
      "MAE: 1593.86\n",
      "MAE: 1593.94\n",
      "MAE: 1594.26\n",
      "MAE: 1594.38\n",
      "MAE: 1590.41\n",
      "MAE: 1590.98\n",
      "MAE: 1584.89\n",
      "MAE: 1578.04\n",
      "MAE: 1571.18\n",
      "MAE: 1565.95\n",
      "MAE: 1567.10\n",
      "MAE: 1562.54\n",
      "MAE: 1561.87\n",
      "MAE: 1553.44\n",
      "MAE: 1534.32\n",
      "MAE: 1533.04\n",
      "MAE: 1532.00\n",
      "MAE: 1530.77\n",
      "MAE: 1534.66\n",
      "MAE: 1537.01\n",
      "MAE: 1530.76\n",
      "MAE: 1532.52\n",
      "MAE: 1530.72\n",
      "MAE: 1531.18\n",
      "MAE: 1529.94\n",
      "MAE: 1530.37\n",
      "MAE: 1528.43\n",
      "MAE: 1532.05\n",
      "MAE: 1532.21\n",
      "MAE: 1531.59\n",
      "MAE: 1532.80\n",
      "MAE: 1533.65\n",
      "MAE: 1536.72\n",
      "MAE: 1534.52\n",
      "MAE: 1534.60\n",
      "MAE: 1530.93\n",
      "MAE: 1530.84\n",
      "MAE: 1531.02\n",
      "MAE: 1532.26\n",
      "MAE: 1532.04\n",
      "MAE: 1532.59\n",
      "MAE: 1535.10\n",
      "MAE: 1530.78\n",
      "MAE: 1534.96\n",
      "MAE: 1532.64\n",
      "MAE: 1534.36\n",
      "MAE: 1531.89\n",
      "MAE: 1533.35\n",
      "MAE: 1557.64\n",
      "MAE: 1544.02\n",
      "MAE: 1533.34\n",
      "MAE: 1540.71\n",
      "MAE: 1533.09\n",
      "MAE: 1543.55\n",
      "MAE: 1535.72\n",
      "MAE: 1537.83\n",
      "MAE: 1540.93\n",
      "MAE: 1535.21\n",
      "MAE: 1544.33\n",
      "MAE: 1537.83\n",
      "MAE: 1539.17\n",
      "MAE: 1536.05\n",
      "MAE: 1536.94\n",
      "MAE: 1540.58\n",
      "MAE: 1543.41\n",
      "MAE: 1540.31\n",
      "MAE: 1539.48\n",
      "MAE: 1537.21\n",
      "MAE: 1536.57\n",
      "MAE: 1539.56\n",
      "MAE: 1532.63\n",
      "MAE: 1540.00\n",
      "MAE: 1535.89\n",
      "MAE: 1538.86\n",
      "MAE: 1535.29\n",
      "MAE: 1533.34\n",
      "MAE: 1538.91\n",
      "MAE: 1536.33\n",
      "MAE: 1538.78\n",
      "MAE: 1539.05\n",
      "MAE: 1538.73\n",
      "MAE: 1538.78\n",
      "MAE: 1535.51\n",
      "MAE: 1536.46\n",
      "MAE: 1529.79\n",
      "MAE: 1537.05\n",
      "MAE: 1539.92\n",
      "MAE: 1540.65\n",
      "MAE: 1539.22\n",
      "MAE: 1533.22\n",
      "MAE: 1534.65\n",
      "MAE: 1537.50\n",
      "MAE: 1537.20\n",
      "MAE: 1535.57\n",
      "MAE: 1534.27\n",
      "MAE: 1532.95\n",
      "MAE: 1534.54\n",
      "MAE: 1535.95\n",
      "MAE: 1538.96\n",
      "MAE: 1536.19\n",
      "MAE: 1534.65\n",
      "MAE: 1532.01\n",
      "MAE: 1532.42\n",
      "MAE: 1535.54\n",
      "MAE: 1532.88\n",
      "MAE: 1534.37\n",
      "MAE: 1530.27\n",
      "MAE: 1532.06\n",
      "MAE: 1533.02\n",
      "MAE: 1530.00\n",
      "MAE: 1532.00\n",
      "MAE: 1531.77\n",
      "MAE: 1530.37\n",
      "MAE: 1532.52\n",
      "MAE: 1533.63\n",
      "MAE: 1532.13\n",
      "MAE: 1530.77\n",
      "MAE: 1535.81\n",
      "MAE: 1535.45\n",
      "MAE: 1535.20\n",
      "MAE: 1536.40\n",
      "MAE: 1533.59\n",
      "MAE: 1532.04\n",
      "MAE: 1530.87\n",
      "MAE: 1530.80\n",
      "MAE: 1535.02\n",
      "MAE: 1537.94\n",
      "MAE: 1537.26\n",
      "MAE: 1537.26\n",
      "MAE: 1535.93\n",
      "MAE: 1535.45\n",
      "MAE: 1534.35\n",
      "MAE: 1534.03\n",
      "MAE: 1531.27\n",
      "MAE: 1532.14\n",
      "MAE: 1532.09\n",
      "MAE: 1534.26\n",
      "MAE: 1535.72\n",
      "MAE: 1535.73\n",
      "MAE: 1536.29\n",
      "MAE: 1534.37\n",
      "MAE: 1533.37\n",
      "MAE: 1533.31\n",
      "MAE: 1532.68\n",
      "MAE: 1535.24\n",
      "MAE: 1531.97\n",
      "MAE: 1532.92\n",
      "MAE: 1536.14\n",
      "MAE: 1535.08\n",
      "MAE: 1533.81\n",
      "MAE: 1534.20\n",
      "MAE: 1534.05\n",
      "MAE: 1534.42\n",
      "MAE: 1533.63\n",
      "MAE: 1534.67\n",
      "MAE: 1534.26\n",
      "MAE: 1534.30\n",
      "MAE: 1535.15\n",
      "MAE: 1536.18\n",
      "MAE: 1535.90\n",
      "MAE: 1534.31\n",
      "MAE: 1531.12\n",
      "MAE: 1532.88\n",
      "MAE: 1532.49\n",
      "MAE: 1517.95\n",
      "MAE: 1519.80\n",
      "MAE: 1507.57\n",
      "MAE: 1508.25\n",
      "MAE: 1507.58\n",
      "MAE: 1507.35\n",
      "MAE: 1507.68\n",
      "MAE: 1506.36\n",
      "MAE: 1508.23\n",
      "MAE: 1506.82\n",
      "MAE: 1507.86\n",
      "MAE: 1501.64\n",
      "MAE: 1502.03\n",
      "MAE: 1502.87\n",
      "MAE: 1501.74\n",
      "MAE: 1501.61\n",
      "MAE: 1501.02\n",
      "MAE: 1502.96\n",
      "MAE: 1501.28\n",
      "MAE: 1500.91\n",
      "MAE: 1501.59\n",
      "MAE: 1502.19\n",
      "MAE: 1501.59\n",
      "MAE: 1501.70\n",
      "MAE: 1501.85\n",
      "MAE: 1501.62\n",
      "MAE: 1502.18\n",
      "MAE: 1502.31\n",
      "MAE: 1501.17\n",
      "MAE: 1502.30\n",
      "MAE: 1487.59\n",
      "MAE: 1487.66\n",
      "MAE: 1487.99\n",
      "MAE: 1488.10\n",
      "MAE: 1488.12\n",
      "MAE: 1486.87\n",
      "MAE: 1489.73\n",
      "MAE: 1485.82\n",
      "MAE: 1466.59\n",
      "MAE: 1460.10\n",
      "MAE: 1438.43\n",
      "MAE: 1437.05\n",
      "MAE: 1437.01\n",
      "MAE: 1436.28\n",
      "MAE: 1437.62\n",
      "MAE: 1437.90\n",
      "MAE: 1436.89\n",
      "MAE: 1436.82\n",
      "MAE: 1438.70\n",
      "MAE: 1437.13\n",
      "MAE: 1439.10\n",
      "MAE: 1439.66\n",
      "MAE: 1434.23\n",
      "MAE: 1438.10\n",
      "MAE: 1435.10\n",
      "MAE: 1437.94\n",
      "MAE: 1437.89\n",
      "MAE: 1437.63\n",
      "MAE: 1438.28\n",
      "MAE: 1437.20\n",
      "MAE: 1436.54\n",
      "MAE: 1438.81\n",
      "MAE: 1437.41\n",
      "MAE: 1436.39\n",
      "MAE: 1438.60\n",
      "MAE: 1436.74\n",
      "MAE: 1438.36\n",
      "MAE: 1437.14\n",
      "MAE: 1435.39\n",
      "MAE: 1435.79\n",
      "MAE: 1435.24\n",
      "MAE: 1439.31\n",
      "MAE: 1436.89\n",
      "MAE: 1436.59\n",
      "MAE: 1435.60\n",
      "MAE: 1434.58\n",
      "MAE: 1440.17\n",
      "MAE: 1437.53\n",
      "MAE: 1439.66\n",
      "MAE: 1437.35\n",
      "MAE: 1443.02\n",
      "MAE: 1437.99\n",
      "MAE: 1438.61\n",
      "MAE: 1443.10\n",
      "MAE: 1441.25\n",
      "MAE: 1438.33\n",
      "MAE: 1438.67\n",
      "MAE: 1437.57\n",
      "MAE: 1437.70\n",
      "MAE: 1436.32\n",
      "MAE: 1437.80\n",
      "MAE: 1437.77\n",
      "MAE: 1436.69\n",
      "MAE: 1437.48\n",
      "MAE: 1437.35\n",
      "MAE: 1436.33\n",
      "MAE: 1436.28\n",
      "MAE: 1438.46\n",
      "MAE: 1437.70\n",
      "MAE: 1436.10\n",
      "MAE: 1436.59\n",
      "MAE: 1437.74\n",
      "MAE: 1436.77\n",
      "MAE: 1436.73\n",
      "MAE: 1436.92\n",
      "MAE: 1435.43\n",
      "MAE: 1436.45\n",
      "MAE: 1436.62\n",
      "MAE: 1435.62\n",
      "MAE: 1434.97\n",
      "MAE: 1434.64\n",
      "MAE: 1434.73\n",
      "MAE: 1436.64\n",
      "MAE: 1433.31\n",
      "MAE: 1435.89\n",
      "MAE: 1434.86\n",
      "MAE: 1439.77\n",
      "MAE: 1433.28\n",
      "MAE: 1433.70\n",
      "MAE: 1436.27\n",
      "MAE: 1434.62\n",
      "MAE: 1435.73\n",
      "MAE: 1433.77\n",
      "MAE: 1433.70\n",
      "MAE: 1436.88\n",
      "MAE: 1430.83\n",
      "MAE: 1432.28\n",
      "MAE: 1433.01\n",
      "MAE: 1443.60\n",
      "MAE: 1438.28\n",
      "MAE: 1436.89\n",
      "MAE: 1435.74\n",
      "MAE: 1443.53\n",
      "MAE: 1434.40\n",
      "MAE: 1439.23\n",
      "MAE: 1446.91\n",
      "MAE: 1442.94\n",
      "MAE: 1448.95\n",
      "MAE: 1443.27\n",
      "MAE: 1444.31\n",
      "MAE: 1437.74\n",
      "MAE: 1439.36\n",
      "MAE: 1443.32\n",
      "MAE: 1443.32\n",
      "MAE: 1447.51\n",
      "MAE: 1441.72\n",
      "MAE: 1434.96\n",
      "MAE: 1437.59\n",
      "MAE: 1441.14\n",
      "MAE: 1439.52\n",
      "MAE: 1446.06\n",
      "MAE: 1440.44\n",
      "MAE: 1440.94\n",
      "MAE: 1445.98\n",
      "MAE: 1438.56\n",
      "MAE: 1445.19\n",
      "MAE: 1440.91\n",
      "MAE: 1439.00\n",
      "MAE: 1443.44\n",
      "MAE: 1440.56\n",
      "MAE: 1443.32\n",
      "MAE: 1442.94\n",
      "MAE: 1442.98\n",
      "MAE: 1443.11\n",
      "MAE: 1443.51\n",
      "MAE: 1444.54\n",
      "MAE: 1435.74\n",
      "MAE: 1436.02\n",
      "MAE: 1434.11\n",
      "MAE: 1437.40\n",
      "MAE: 1436.30\n",
      "MAE: 1437.30\n",
      "MAE: 1435.19\n",
      "MAE: 1435.55\n",
      "MAE: 1435.09\n",
      "MAE: 1435.49\n",
      "MAE: 1435.85\n",
      "MAE: 1435.92\n",
      "MAE: 1430.67\n",
      "MAE: 1437.48\n",
      "MAE: 1436.46\n",
      "MAE: 1434.00\n",
      "MAE: 1439.11\n",
      "MAE: 1434.85\n",
      "MAE: 1437.47\n",
      "MAE: 1438.62\n",
      "MAE: 1437.22\n",
      "MAE: 1437.63\n",
      "MAE: 1436.25\n",
      "MAE: 1438.73\n",
      "MAE: 1439.97\n",
      "MAE: 1437.59\n",
      "MAE: 1436.96\n",
      "MAE: 1437.85\n",
      "MAE: 1436.54\n",
      "MAE: 1434.25\n",
      "MAE: 1434.30\n",
      "MAE: 1438.35\n",
      "MAE: 1435.17\n",
      "MAE: 1440.84\n",
      "MAE: 1437.90\n",
      "MAE: 1436.39\n",
      "MAE: 1442.24\n",
      "MAE: 1440.30\n",
      "MAE: 1435.41\n",
      "MAE: 1435.09\n",
      "MAE: 1435.51\n",
      "MAE: 1436.66\n",
      "MAE: 1436.49\n",
      "MAE: 1438.75\n",
      "MAE: 1440.29\n",
      "MAE: 1437.37\n",
      "MAE: 1436.97\n",
      "MAE: 1438.30\n",
      "MAE: 1434.48\n",
      "MAE: 1436.45\n",
      "MAE: 1436.56\n",
      "MAE: 1436.67\n",
      "MAE: 1438.01\n",
      "MAE: 1437.44\n",
      "MAE: 1438.78\n",
      "MAE: 1437.09\n",
      "MAE: 1436.02\n",
      "MAE: 1438.75\n",
      "MAE: 1435.68\n",
      "MAE: 1437.95\n",
      "MAE: 1436.91\n",
      "MAE: 1437.82\n",
      "MAE: 1439.90\n",
      "MAE: 1437.37\n",
      "MAE: 1437.52\n",
      "MAE: 1447.24\n",
      "MAE: 1438.50\n",
      "MAE: 1439.02\n",
      "MAE: 1437.05\n",
      "MAE: 1438.44\n",
      "MAE: 1436.74\n",
      "MAE: 1438.86\n",
      "MAE: 1439.60\n",
      "MAE: 1441.18\n",
      "MAE: 1443.46\n",
      "MAE: 1442.31\n",
      "MAE: 1438.72\n",
      "MAE: 1435.78\n",
      "MAE: 1433.12\n",
      "MAE: 1435.06\n",
      "MAE: 1435.57\n",
      "MAE: 1436.01\n",
      "MAE: 1436.00\n",
      "MAE: 1434.18\n",
      "MAE: 1436.30\n",
      "MAE: 1434.63\n",
      "MAE: 1434.68\n",
      "MAE: 1433.62\n",
      "MAE: 1437.88\n",
      "MAE: 1437.30\n",
      "MAE: 1434.69\n",
      "MAE: 1438.72\n",
      "MAE: 1437.67\n",
      "MAE: 1435.87\n",
      "MAE: 1436.69\n",
      "MAE: 1436.23\n",
      "MAE: 1436.04\n",
      "MAE: 1437.34\n",
      "MAE: 1435.17\n",
      "MAE: 1435.82\n",
      "MAE: 1436.08\n",
      "MAE: 1436.85\n",
      "MAE: 1436.41\n",
      "MAE: 1436.14\n",
      "MAE: 1436.29\n",
      "MAE: 1438.77\n",
      "MAE: 1438.93\n",
      "MAE: 1439.39\n",
      "MAE: 1438.85\n",
      "MAE: 1438.65\n",
      "MAE: 1438.13\n",
      "MAE: 1439.97\n",
      "MAE: 1436.53\n",
      "MAE: 1436.40\n",
      "MAE: 1438.96\n",
      "MAE: 1436.77\n",
      "MAE: 1435.76\n",
      "MAE: 1437.00\n",
      "MAE: 1433.88\n",
      "MAE: 1442.56\n",
      "MAE: 1438.53\n",
      "MAE: 1439.36\n",
      "MAE: 1438.33\n",
      "MAE: 1437.87\n",
      "MAE: 1437.92\n",
      "MAE: 1436.44\n",
      "MAE: 1435.08\n",
      "MAE: 1437.17\n",
      "MAE: 1436.90\n",
      "MAE: 1436.44\n",
      "MAE: 1434.12\n",
      "MAE: 1435.68\n",
      "MAE: 1435.15\n",
      "MAE: 1435.97\n",
      "MAE: 1434.73\n",
      "MAE: 1436.55\n",
      "MAE: 1435.32\n",
      "MAE: 1438.62\n",
      "MAE: 1437.84\n",
      "MAE: 1433.65\n",
      "MAE: 1436.13\n",
      "MAE: 1435.75\n",
      "MAE: 1434.83\n",
      "MAE: 1436.15\n",
      "MAE: 1435.92\n",
      "MAE: 1438.37\n",
      "MAE: 1434.66\n",
      "MAE: 1434.80\n",
      "MAE: 1433.09\n",
      "MAE: 1439.26\n",
      "MAE: 1437.48\n",
      "MAE: 1437.38\n",
      "MAE: 1433.77\n",
      "MAE: 1434.35\n",
      "MAE: 1434.64\n",
      "MAE: 1437.85\n",
      "MAE: 1435.11\n",
      "MAE: 1436.23\n",
      "MAE: 1434.58\n",
      "MAE: 1435.10\n",
      "MAE: 1434.52\n",
      "MAE: 1436.05\n",
      "MAE: 1435.40\n",
      "MAE: 1434.45\n",
      "MAE: 1434.28\n",
      "MAE: 1436.66\n",
      "MAE: 1436.20\n",
      "MAE: 1435.86\n",
      "MAE: 1436.12\n",
      "MAE: 1436.47\n",
      "MAE: 1437.06\n",
      "MAE: 1434.98\n",
      "MAE: 1435.46\n",
      "MAE: 1436.65\n",
      "MAE: 1436.95\n",
      "MAE: 1437.42\n",
      "MAE: 1433.86\n",
      "MAE: 1435.73\n",
      "MAE: 1436.21\n",
      "MAE: 1436.57\n",
      "MAE: 1436.65\n",
      "MAE: 1434.46\n",
      "MAE: 1434.70\n",
      "MAE: 1436.39\n",
      "MAE: 1435.79\n",
      "MAE: 1435.41\n",
      "MAE: 1434.71\n",
      "MAE: 1436.48\n",
      "MAE: 1435.46\n",
      "MAE: 1436.85\n",
      "MAE: 1437.94\n",
      "MAE: 1436.49\n",
      "MAE: 1437.94\n",
      "MAE: 1438.35\n",
      "MAE: 1438.33\n",
      "MAE: 1435.86\n",
      "MAE: 1437.37\n",
      "MAE: 1436.55\n",
      "MAE: 1436.76\n",
      "MAE: 1439.25\n",
      "MAE: 1437.74\n",
      "MAE: 1437.50\n",
      "MAE: 1436.42\n",
      "MAE: 1437.34\n",
      "MAE: 1438.11\n",
      "MAE: 1436.12\n",
      "MAE: 1436.44\n",
      "MAE: 1438.14\n",
      "MAE: 1438.10\n",
      "MAE: 1436.73\n",
      "MAE: 1437.40\n",
      "MAE: 1436.94\n",
      "MAE: 1437.60\n",
      "MAE: 1437.24\n",
      "MAE: 1437.83\n",
      "MAE: 1436.00\n",
      "MAE: 1438.04\n",
      "MAE: 1438.59\n",
      "MAE: 1438.67\n",
      "MAE: 1437.98\n",
      "MAE: 1434.50\n",
      "MAE: 1434.52\n",
      "MAE: 1435.19\n",
      "MAE: 1435.65\n",
      "MAE: 1434.64\n",
      "MAE: 1434.75\n",
      "MAE: 1436.36\n",
      "MAE: 1436.79\n",
      "MAE: 1434.47\n",
      "MAE: 1435.63\n",
      "MAE: 1434.09\n",
      "MAE: 1435.59\n",
      "MAE: 1435.57\n",
      "MAE: 1433.27\n",
      "MAE: 1433.43\n",
      "MAE: 1436.48\n",
      "MAE: 1433.18\n",
      "MAE: 1435.47\n",
      "MAE: 1434.83\n",
      "MAE: 1435.29\n",
      "MAE: 1436.78\n",
      "MAE: 1433.65\n",
      "MAE: 1434.64\n",
      "MAE: 1437.02\n",
      "MAE: 1434.93\n",
      "MAE: 1434.70\n",
      "MAE: 1434.91\n",
      "MAE: 1435.31\n",
      "MAE: 1436.15\n",
      "MAE: 1437.06\n",
      "MAE: 1438.14\n",
      "MAE: 1436.49\n",
      "MAE: 1435.54\n",
      "MAE: 1436.33\n",
      "MAE: 1435.24\n",
      "MAE: 1436.21\n",
      "MAE: 1434.32\n",
      "MAE: 1434.39\n",
      "MAE: 1434.32\n",
      "MAE: 1433.87\n",
      "MAE: 1435.64\n",
      "MAE: 1435.41\n",
      "MAE: 1434.04\n",
      "MAE: 1435.64\n",
      "MAE: 1435.47\n",
      "MAE: 1435.61\n",
      "MAE: 1434.14\n",
      "MAE: 1434.51\n",
      "MAE: 1433.72\n",
      "MAE: 1433.69\n",
      "MAE: 1434.09\n",
      "MAE: 1434.38\n",
      "MAE: 1433.72\n",
      "MAE: 1433.87\n",
      "MAE: 1434.74\n",
      "MAE: 1433.21\n",
      "MAE: 1432.10\n",
      "MAE: 1431.78\n",
      "MAE: 1432.31\n",
      "MAE: 1432.52\n",
      "MAE: 1436.07\n",
      "MAE: 1432.16\n",
      "MAE: 1434.16\n",
      "MAE: 1435.01\n",
      "MAE: 1435.37\n",
      "MAE: 1435.10\n",
      "MAE: 1435.29\n",
      "MAE: 1436.49\n",
      "MAE: 1435.35\n",
      "MAE: 1434.51\n",
      "MAE: 1431.70\n",
      "MAE: 1434.96\n",
      "MAE: 1432.97\n",
      "MAE: 1432.00\n",
      "MAE: 1431.79\n",
      "MAE: 1432.58\n",
      "MAE: 1431.72\n",
      "MAE: 1433.88\n",
      "MAE: 1437.57\n",
      "MAE: 1434.02\n",
      "MAE: 1434.29\n",
      "MAE: 1431.97\n",
      "MAE: 1431.65\n",
      "MAE: 1433.21\n",
      "MAE: 1433.63\n",
      "MAE: 1433.89\n",
      "MAE: 1432.82\n",
      "MAE: 1433.70\n",
      "MAE: 1433.90\n",
      "MAE: 1435.04\n",
      "MAE: 1434.45\n",
      "MAE: 1434.60\n",
      "MAE: 1433.76\n",
      "MAE: 1433.80\n",
      "MAE: 1434.70\n",
      "MAE: 1435.25\n",
      "MAE: 1434.75\n",
      "MAE: 1433.11\n",
      "MAE: 1433.84\n",
      "MAE: 1435.12\n",
      "MAE: 1434.38\n",
      "MAE: 1435.29\n",
      "MAE: 1433.99\n",
      "MAE: 1434.98\n",
      "MAE: 1433.99\n",
      "MAE: 1434.37\n",
      "MAE: 1434.39\n",
      "MAE: 1433.92\n",
      "MAE: 1434.47\n",
      "MAE: 1434.18\n",
      "MAE: 1435.18\n",
      "MAE: 1434.29\n",
      "MAE: 1433.00\n",
      "MAE: 1435.84\n",
      "MAE: 1434.25\n",
      "MAE: 1433.91\n",
      "MAE: 1434.29\n",
      "MAE: 1434.20\n",
      "MAE: 1434.40\n",
      "MAE: 1434.39\n",
      "MAE: 1433.38\n",
      "MAE: 1432.82\n",
      "MAE: 1433.76\n",
      "MAE: 1435.09\n",
      "MAE: 1435.61\n",
      "MAE: 1434.50\n",
      "MAE: 1434.54\n",
      "MAE: 1434.81\n",
      "MAE: 1433.90\n",
      "MAE: 1434.47\n",
      "MAE: 1433.89\n",
      "MAE: 1433.93\n",
      "MAE: 1433.96\n",
      "MAE: 1434.51\n",
      "MAE: 1435.43\n",
      "MAE: 1433.90\n",
      "MAE: 1435.38\n",
      "MAE: 1433.63\n",
      "MAE: 1434.01\n",
      "MAE: 1433.14\n",
      "MAE: 1435.38\n",
      "MAE: 1435.29\n",
      "MAE: 1436.86\n",
      "MAE: 1437.90\n",
      "MAE: 1437.83\n",
      "MAE: 1437.42\n",
      "MAE: 1438.14\n",
      "MAE: 1436.63\n",
      "MAE: 1437.49\n",
      "MAE: 1435.34\n",
      "MAE: 1437.37\n",
      "MAE: 1437.76\n",
      "MAE: 1435.19\n",
      "MAE: 1436.52\n",
      "MAE: 1438.88\n",
      "MAE: 1435.06\n",
      "MAE: 1436.18\n",
      "MAE: 1439.02\n",
      "MAE: 1436.85\n",
      "MAE: 1435.52\n",
      "MAE: 1434.55\n",
      "MAE: 1438.49\n",
      "MAE: 1434.89\n",
      "MAE: 1436.56\n",
      "MAE: 1436.25\n",
      "MAE: 1435.36\n",
      "MAE: 1435.15\n",
      "MAE: 1434.85\n",
      "MAE: 1435.71\n",
      "MAE: 1440.89\n",
      "MAE: 1439.46\n",
      "MAE: 1437.60\n",
      "MAE: 1434.94\n",
      "MAE: 1435.96\n",
      "MAE: 1436.45\n",
      "MAE: 1436.84\n",
      "MAE: 1436.07\n",
      "MAE: 1437.81\n",
      "MAE: 1436.76\n",
      "MAE: 1435.25\n",
      "MAE: 1437.27\n",
      "MAE: 1436.78\n",
      "MAE: 1447.38\n",
      "MAE: 1449.04\n",
      "MAE: 1449.18\n",
      "MAE: 1447.02\n",
      "MAE: 1450.47\n",
      "MAE: 1446.74\n",
      "MAE: 1448.73\n",
      "MAE: 1446.14\n",
      "MAE: 1449.18\n",
      "MAE: 1449.55\n",
      "MAE: 1453.78\n",
      "MAE: 1455.84\n",
      "MAE: 1455.40\n",
      "MAE: 1458.55\n",
      "MAE: 1461.55\n",
      "MAE: 1486.91\n",
      "MAE: 1490.41\n",
      "MAE: 1492.19\n",
      "MAE: 1493.77\n",
      "MAE: 1499.67\n",
      "MAE: 1498.57\n",
      "MAE: 1499.12\n",
      "MAE: 1498.37\n",
      "MAE: 1499.12\n",
      "MAE: 1498.66\n",
      "MAE: 1500.24\n",
      "MAE: 1495.70\n",
      "MAE: 1498.72\n",
      "MAE: 1498.63\n",
      "MAE: 1498.13\n",
      "MAE: 1499.89\n",
      "MAE: 1497.72\n",
      "MAE: 1498.88\n",
      "MAE: 1498.59\n",
      "MAE: 1497.33\n",
      "MAE: 1497.00\n",
      "MAE: 1497.40\n",
      "MAE: 1497.76\n",
      "MAE: 1496.88\n",
      "MAE: 1497.85\n",
      "MAE: 1498.24\n",
      "MAE: 1500.06\n",
      "MAE: 1499.75\n",
      "MAE: 1498.74\n",
      "MAE: 1499.44\n",
      "MAE: 1499.25\n",
      "MAE: 1500.03\n",
      "MAE: 1505.80\n",
      "MAE: 1505.90\n",
      "MAE: 1506.26\n",
      "MAE: 1508.76\n",
      "MAE: 1508.93\n",
      "MAE: 1507.98\n",
      "MAE: 1508.82\n",
      "MAE: 1507.51\n",
      "MAE: 1510.98\n",
      "MAE: 1510.20\n",
      "MAE: 1510.18\n",
      "MAE: 1510.75\n",
      "MAE: 1511.30\n",
      "MAE: 1510.70\n",
      "MAE: 1512.52\n",
      "MAE: 1512.35\n",
      "MAE: 1515.34\n",
      "MAE: 1515.64\n",
      "MAE: 1515.78\n",
      "MAE: 1515.77\n",
      "MAE: 1516.88\n",
      "MAE: 1515.69\n",
      "MAE: 1516.69\n",
      "MAE: 1516.42\n",
      "MAE: 1516.23\n",
      "MAE: 1515.59\n",
      "MAE: 1515.64\n",
      "MAE: 1516.09\n",
      "MAE: 1516.20\n",
      "MAE: 1516.02\n",
      "MAE: 1515.92\n",
      "MAE: 1514.39\n",
      "MAE: 1512.83\n",
      "MAE: 1510.67\n",
      "MAE: 1510.69\n",
      "MAE: 1510.66\n",
      "MAE: 1510.79\n",
      "MAE: 1508.94\n",
      "MAE: 1508.19\n",
      "MAE: 1508.36\n",
      "MAE: 1508.12\n",
      "MAE: 1508.48\n",
      "MAE: 1508.16\n",
      "MAE: 1508.75\n",
      "MAE: 1508.99\n",
      "MAE: 1509.15\n",
      "MAE: 1508.55\n",
      "MAE: 1508.51\n",
      "MAE: 1509.02\n",
      "MAE: 1508.29\n",
      "MAE: 1508.44\n",
      "MAE: 1508.67\n",
      "MAE: 1507.95\n",
      "MAE: 1509.55\n",
      "MAE: 1509.55\n",
      "MAE: 1508.71\n",
      "MAE: 1508.27\n",
      "MAE: 1508.16\n",
      "MAE: 1508.25\n",
      "MAE: 1508.36\n",
      "MAE: 1508.72\n",
      "MAE: 1508.52\n",
      "MAE: 1508.43\n",
      "MAE: 1508.38\n",
      "MAE: 1508.69\n",
      "MAE: 1508.66\n",
      "MAE: 1508.96\n",
      "MAE: 1510.55\n",
      "MAE: 1509.93\n",
      "MAE: 1508.73\n",
      "MAE: 1508.13\n",
      "MAE: 1509.91\n",
      "MAE: 1507.49\n",
      "MAE: 1509.13\n",
      "MAE: 1508.15\n",
      "MAE: 1508.74\n",
      "MAE: 1509.31\n",
      "MAE: 1509.14\n",
      "MAE: 1509.16\n",
      "MAE: 1508.78\n",
      "MAE: 1509.26\n",
      "MAE: 1508.31\n",
      "MAE: 1508.71\n",
      "MAE: 1509.09\n",
      "MAE: 1509.44\n",
      "MAE: 1508.68\n",
      "MAE: 1508.68\n",
      "MAE: 1509.28\n",
      "MAE: 1509.19\n",
      "MAE: 1509.46\n",
      "MAE: 1508.31\n",
      "MAE: 1508.48\n",
      "MAE: 1508.56\n",
      "MAE: 1508.40\n",
      "MAE: 1509.33\n",
      "MAE: 1508.55\n",
      "MAE: 1509.01\n",
      "MAE: 1508.90\n",
      "MAE: 1509.07\n",
      "MAE: 1508.69\n",
      "MAE: 1508.90\n",
      "MAE: 1508.50\n",
      "MAE: 1508.61\n",
      "MAE: 1508.50\n",
      "MAE: 1508.34\n",
      "MAE: 1507.80\n",
      "MAE: 1509.29\n",
      "MAE: 1508.51\n",
      "MAE: 1508.34\n",
      "MAE: 1509.07\n",
      "MAE: 1509.63\n",
      "MAE: 1508.94\n",
      "MAE: 1508.44\n",
      "MAE: 1508.34\n",
      "MAE: 1508.54\n",
      "MAE: 1508.88\n",
      "MAE: 1508.19\n",
      "MAE: 1507.90\n",
      "MAE: 1507.94\n",
      "MAE: 1508.13\n",
      "MAE: 1508.03\n",
      "MAE: 1508.66\n",
      "MAE: 1508.16\n",
      "MAE: 1507.66\n",
      "MAE: 1508.41\n",
      "MAE: 1508.34\n",
      "MAE: 1507.62\n",
      "MAE: 1507.39\n",
      "MAE: 1507.80\n",
      "MAE: 1507.78\n",
      "MAE: 1507.24\n",
      "MAE: 1508.62\n",
      "MAE: 1507.28\n",
      "MAE: 1507.46\n",
      "MAE: 1507.61\n",
      "MAE: 1507.68\n",
      "MAE: 1507.12\n",
      "MAE: 1507.83\n",
      "MAE: 1507.49\n",
      "MAE: 1508.03\n",
      "MAE: 1507.73\n",
      "MAE: 1507.61\n",
      "MAE: 1507.87\n",
      "MAE: 1508.13\n",
      "MAE: 1507.78\n",
      "MAE: 1507.95\n",
      "MAE: 1507.59\n",
      "MAE: 1508.20\n",
      "MAE: 1507.42\n",
      "MAE: 1507.19\n",
      "MAE: 1507.08\n",
      "MAE: 1507.80\n",
      "MAE: 1507.60\n",
      "MAE: 1507.03\n",
      "MAE: 1507.20\n",
      "MAE: 1508.05\n",
      "MAE: 1507.80\n",
      "MAE: 1507.97\n",
      "MAE: 1507.90\n",
      "MAE: 1509.83\n",
      "MAE: 1510.31\n",
      "MAE: 1509.37\n",
      "MAE: 1509.07\n",
      "MAE: 1508.33\n",
      "MAE: 1508.93\n",
      "MAE: 1507.79\n",
      "MAE: 1508.87\n",
      "MAE: 1509.28\n",
      "MAE: 1508.52\n",
      "MAE: 1508.16\n",
      "MAE: 1508.30\n",
      "MAE: 1508.27\n",
      "MAE: 1508.49\n",
      "MAE: 1508.89\n",
      "MAE: 1509.09\n",
      "MAE: 1509.21\n",
      "MAE: 1508.39\n",
      "MAE: 1510.11\n",
      "MAE: 1509.75\n",
      "MAE: 1509.44\n",
      "MAE: 1509.21\n",
      "MAE: 1509.19\n",
      "MAE: 1509.10\n",
      "MAE: 1508.98\n",
      "MAE: 1508.75\n",
      "MAE: 1508.30\n",
      "MAE: 1507.73\n",
      "MAE: 1508.21\n",
      "MAE: 1508.49\n",
      "MAE: 1508.85\n",
      "MAE: 1508.50\n",
      "MAE: 1509.97\n",
      "MAE: 1508.83\n",
      "MAE: 1508.07\n",
      "MAE: 1509.08\n",
      "MAE: 1508.99\n",
      "MAE: 1509.10\n",
      "MAE: 1509.67\n",
      "MAE: 1509.47\n",
      "MAE: 1509.20\n",
      "MAE: 1509.50\n",
      "MAE: 1509.20\n",
      "MAE: 1508.88\n",
      "MAE: 1508.76\n",
      "MAE: 1508.60\n",
      "MAE: 1508.73\n",
      "MAE: 1508.01\n",
      "MAE: 1507.99\n",
      "MAE: 1508.27\n",
      "MAE: 1508.40\n",
      "MAE: 1507.57\n",
      "MAE: 1507.77\n",
      "MAE: 1507.38\n",
      "MAE: 1506.91\n",
      "MAE: 1507.92\n",
      "MAE: 1508.58\n",
      "MAE: 1507.78\n",
      "MAE: 1507.96\n",
      "MAE: 1507.87\n",
      "MAE: 1508.08\n",
      "MAE: 1508.40\n",
      "MAE: 1507.50\n",
      "MAE: 1508.26\n",
      "MAE: 1509.09\n",
      "MAE: 1507.58\n",
      "MAE: 1508.09\n",
      "MAE: 1508.88\n",
      "MAE: 1508.87\n",
      "MAE: 1508.65\n",
      "MAE: 1509.52\n",
      "MAE: 1507.74\n",
      "MAE: 1507.94\n",
      "MAE: 1508.91\n",
      "MAE: 1509.34\n",
      "MAE: 1507.91\n",
      "MAE: 1508.63\n",
      "MAE: 1509.39\n",
      "MAE: 1509.00\n",
      "MAE: 1508.38\n",
      "MAE: 1509.44\n",
      "MAE: 1508.34\n",
      "MAE: 1508.39\n",
      "MAE: 1508.76\n",
      "MAE: 1508.01\n",
      "MAE: 1508.61\n",
      "MAE: 1508.93\n",
      "MAE: 1508.89\n",
      "MAE: 1508.76\n",
      "MAE: 1508.56\n",
      "MAE: 1509.62\n",
      "MAE: 1508.51\n",
      "MAE: 1508.60\n",
      "MAE: 1509.57\n",
      "MAE: 1509.23\n",
      "MAE: 1509.01\n",
      "MAE: 1509.16\n",
      "MAE: 1509.04\n",
      "MAE: 1509.08\n",
      "MAE: 1509.60\n",
      "MAE: 1510.15\n",
      "MAE: 1510.57\n",
      "MAE: 1508.81\n",
      "MAE: 1509.86\n",
      "MAE: 1509.81\n",
      "MAE: 1508.54\n",
      "MAE: 1506.73\n",
      "MAE: 1509.16\n",
      "MAE: 1509.13\n",
      "MAE: 1510.78\n",
      "MAE: 1508.61\n",
      "MAE: 1510.26\n",
      "MAE: 1506.57\n",
      "MAE: 1507.97\n",
      "MAE: 1507.80\n",
      "MAE: 1509.44\n",
      "MAE: 1508.77\n",
      "MAE: 1508.81\n",
      "MAE: 1508.28\n",
      "MAE: 1508.34\n",
      "MAE: 1509.43\n",
      "MAE: 1509.23\n",
      "MAE: 1509.61\n",
      "MAE: 1508.70\n",
      "MAE: 1507.79\n",
      "MAE: 1510.10\n",
      "MAE: 1509.27\n",
      "MAE: 1509.49\n",
      "MAE: 1508.16\n",
      "MAE: 1508.32\n",
      "MAE: 1505.65\n",
      "MAE: 1507.17\n",
      "MAE: 1506.26\n",
      "MAE: 1504.38\n",
      "MAE: 1507.17\n",
      "MAE: 1507.18\n",
      "MAE: 1507.08\n",
      "MAE: 1507.67\n",
      "MAE: 1509.66\n",
      "MAE: 1507.72\n",
      "MAE: 1507.47\n",
      "MAE: 1508.76\n",
      "MAE: 1507.23\n",
      "MAE: 1507.48\n",
      "MAE: 1507.78\n",
      "MAE: 1508.92\n",
      "MAE: 1511.08\n",
      "MAE: 1509.39\n",
      "MAE: 1509.00\n",
      "MAE: 1509.15\n",
      "MAE: 1509.66\n",
      "MAE: 1510.57\n",
      "MAE: 1508.63\n",
      "MAE: 1509.80\n",
      "MAE: 1506.90\n",
      "MAE: 1508.55\n",
      "MAE: 1507.48\n",
      "MAE: 1509.41\n",
      "MAE: 1509.43\n",
      "MAE: 1506.59\n",
      "MAE: 1509.13\n",
      "MAE: 1507.77\n",
      "MAE: 1508.40\n",
      "MAE: 1507.29\n",
      "MAE: 1504.25\n",
      "MAE: 1507.88\n",
      "MAE: 1505.25\n",
      "MAE: 1508.41\n",
      "MAE: 1508.71\n",
      "MAE: 1507.92\n",
      "MAE: 1507.23\n",
      "MAE: 1508.96\n",
      "MAE: 1507.62\n",
      "MAE: 1507.83\n",
      "MAE: 1507.89\n",
      "MAE: 1509.29\n",
      "MAE: 1507.38\n",
      "MAE: 1508.34\n",
      "MAE: 1508.91\n",
      "MAE: 1509.26\n",
      "MAE: 1509.79\n",
      "MAE: 1511.24\n",
      "MAE: 1509.96\n",
      "MAE: 1509.02\n",
      "MAE: 1510.19\n",
      "MAE: 1509.74\n",
      "MAE: 1508.64\n",
      "MAE: 1510.31\n",
      "MAE: 1511.21\n",
      "MAE: 1511.57\n",
      "MAE: 1512.12\n",
      "MAE: 1511.48\n",
      "MAE: 1512.78\n",
      "MAE: 1507.83\n",
      "MAE: 1511.20\n",
      "MAE: 1509.07\n",
      "MAE: 1510.66\n",
      "MAE: 1510.50\n",
      "MAE: 1508.70\n",
      "MAE: 1509.87\n",
      "MAE: 1508.43\n",
      "MAE: 1507.94\n",
      "MAE: 1507.31\n",
      "MAE: 1507.22\n",
      "MAE: 1508.67\n",
      "MAE: 1509.60\n",
      "MAE: 1508.41\n",
      "MAE: 1509.36\n",
      "MAE: 1507.82\n",
      "MAE: 1510.29\n",
      "MAE: 1509.82\n",
      "MAE: 1510.33\n",
      "MAE: 1508.66\n",
      "MAE: 1510.76\n",
      "MAE: 1509.84\n",
      "MAE: 1510.18\n",
      "MAE: 1510.33\n",
      "MAE: 1509.96\n",
      "MAE: 1508.31\n",
      "MAE: 1509.87\n",
      "MAE: 1508.43\n",
      "MAE: 1509.46\n",
      "MAE: 1509.45\n",
      "MAE: 1509.67\n",
      "MAE: 1510.30\n",
      "MAE: 1509.45\n",
      "MAE: 1509.01\n",
      "MAE: 1508.64\n",
      "MAE: 1509.41\n",
      "MAE: 1510.78\n",
      "MAE: 1510.95\n",
      "MAE: 1508.64\n",
      "MAE: 1510.17\n",
      "MAE: 1509.69\n",
      "MAE: 1507.92\n",
      "MAE: 1506.80\n",
      "MAE: 1508.13\n",
      "MAE: 1508.45\n",
      "MAE: 1508.50\n",
      "MAE: 1510.62\n",
      "MAE: 1511.46\n",
      "MAE: 1507.93\n",
      "MAE: 1508.54\n",
      "MAE: 1507.61\n",
      "MAE: 1507.40\n",
      "MAE: 1507.43\n",
      "MAE: 1508.77\n",
      "MAE: 1508.38\n",
      "MAE: 1507.78\n",
      "MAE: 1508.02\n",
      "MAE: 1508.92\n",
      "MAE: 1508.59\n",
      "MAE: 1509.52\n",
      "MAE: 1510.25\n",
      "MAE: 1510.49\n",
      "MAE: 1511.17\n",
      "MAE: 1509.03\n",
      "MAE: 1510.85\n",
      "MAE: 1509.09\n",
      "MAE: 1510.05\n",
      "MAE: 1509.44\n",
      "MAE: 1510.67\n",
      "MAE: 1508.50\n",
      "MAE: 1510.21\n",
      "MAE: 1509.22\n",
      "MAE: 1508.61\n",
      "MAE: 1509.20\n",
      "MAE: 1509.14\n",
      "MAE: 1509.93\n",
      "MAE: 1508.00\n",
      "MAE: 1510.16\n",
      "MAE: 1508.80\n",
      "MAE: 1508.75\n",
      "MAE: 1513.57\n",
      "MAE: 1511.61\n",
      "MAE: 1509.62\n",
      "MAE: 1507.83\n",
      "MAE: 1510.28\n",
      "MAE: 1512.05\n",
      "MAE: 1508.10\n",
      "MAE: 1508.58\n",
      "MAE: 1510.05\n",
      "MAE: 1508.85\n",
      "MAE: 1508.07\n",
      "MAE: 1511.59\n",
      "MAE: 1508.64\n",
      "MAE: 1509.31\n",
      "MAE: 1510.78\n",
      "MAE: 1509.79\n",
      "MAE: 1510.07\n",
      "MAE: 1508.86\n",
      "MAE: 1509.51\n",
      "MAE: 1509.02\n",
      "MAE: 1509.26\n",
      "MAE: 1508.62\n",
      "MAE: 1507.55\n",
      "MAE: 1507.58\n",
      "MAE: 1509.09\n",
      "MAE: 1509.29\n",
      "MAE: 1508.59\n",
      "MAE: 1509.25\n",
      "MAE: 1509.93\n",
      "MAE: 1508.16\n",
      "MAE: 1513.96\n",
      "MAE: 1507.08\n",
      "MAE: 1512.25\n",
      "MAE: 1509.56\n",
      "MAE: 1510.07\n",
      "MAE: 1509.36\n",
      "MAE: 1506.68\n",
      "MAE: 1509.38\n",
      "MAE: 1507.20\n",
      "MAE: 1505.26\n",
      "MAE: 1506.62\n",
      "MAE: 1508.34\n",
      "MAE: 1511.27\n",
      "MAE: 1509.50\n",
      "MAE: 1509.01\n",
      "MAE: 1509.50\n",
      "MAE: 1508.59\n",
      "MAE: 1508.87\n",
      "MAE: 1505.70\n",
      "MAE: 1506.54\n",
      "MAE: 1505.76\n",
      "MAE: 1508.11\n",
      "MAE: 1507.81\n",
      "MAE: 1509.61\n",
      "MAE: 1515.43\n",
      "MAE: 1516.63\n",
      "MAE: 1514.93\n",
      "MAE: 1510.34\n",
      "MAE: 1513.23\n",
      "MAE: 1513.16\n",
      "MAE: 1511.35\n",
      "MAE: 1512.18\n",
      "MAE: 1512.50\n",
      "MAE: 1513.62\n",
      "MAE: 1514.57\n",
      "MAE: 1518.76\n",
      "MAE: 1520.49\n",
      "MAE: 1518.41\n",
      "MAE: 1517.76\n",
      "MAE: 1512.96\n",
      "MAE: 1512.41\n",
      "MAE: 1512.92\n",
      "MAE: 1514.78\n",
      "MAE: 1516.58\n",
      "MAE: 1513.96\n",
      "MAE: 1515.80\n",
      "MAE: 1515.02\n",
      "MAE: 1513.64\n",
      "MAE: 1522.67\n",
      "MAE: 1522.65\n",
      "MAE: 1522.57\n",
      "MAE: 1521.74\n",
      "MAE: 1517.57\n",
      "MAE: 1521.32\n",
      "MAE: 1519.02\n",
      "MAE: 1519.70\n",
      "MAE: 1513.50\n",
      "MAE: 1504.17\n",
      "MAE: 1505.50\n",
      "MAE: 1502.58\n",
      "MAE: 1509.70\n",
      "MAE: 1506.35\n",
      "MAE: 1507.80\n",
      "MAE: 1509.08\n",
      "MAE: 1513.25\n",
      "MAE: 1509.09\n",
      "MAE: 1511.24\n",
      "MAE: 1512.28\n",
      "MAE: 1510.55\n",
      "MAE: 1512.88\n",
      "MAE: 1511.47\n",
      "MAE: 1507.29\n",
      "MAE: 1508.37\n",
      "MAE: 1509.16\n",
      "MAE: 1511.33\n",
      "MAE: 1509.20\n",
      "MAE: 1510.56\n",
      "MAE: 1509.45\n",
      "MAE: 1509.98\n",
      "MAE: 1511.72\n",
      "MAE: 1510.06\n",
      "MAE: 1507.76\n",
      "MAE: 1507.74\n",
      "MAE: 1508.64\n",
      "MAE: 1508.69\n",
      "MAE: 1509.29\n",
      "MAE: 1510.47\n",
      "MAE: 1506.14\n",
      "MAE: 1510.24\n",
      "MAE: 1508.33\n",
      "MAE: 1511.04\n",
      "MAE: 1512.87\n",
      "MAE: 1505.23\n",
      "MAE: 1508.15\n",
      "MAE: 1504.92\n",
      "MAE: 1504.12\n",
      "MAE: 1508.12\n",
      "MAE: 1507.75\n",
      "MAE: 1503.30\n",
      "MAE: 1503.89\n",
      "MAE: 1505.37\n",
      "MAE: 1503.63\n",
      "MAE: 1505.72\n",
      "MAE: 1509.05\n",
      "MAE: 1515.88\n",
      "MAE: 1520.42\n",
      "MAE: 1518.35\n",
      "MAE: 1525.89\n",
      "MAE: 1524.65\n",
      "MAE: 1529.91\n",
      "MAE: 1532.61\n",
      "MAE: 1527.71\n",
      "MAE: 1530.94\n",
      "MAE: 1532.28\n",
      "MAE: 1527.22\n",
      "MAE: 1531.22\n",
      "MAE: 1530.38\n",
      "MAE: 1534.45\n",
      "MAE: 1531.18\n",
      "MAE: 1533.33\n",
      "MAE: 1531.11\n",
      "MAE: 1536.94\n",
      "MAE: 1533.53\n",
      "MAE: 1530.13\n",
      "MAE: 1537.30\n",
      "MAE: 1545.26\n",
      "MAE: 1541.43\n",
      "MAE: 1550.97\n",
      "MAE: 1555.78\n",
      "MAE: 1552.11\n",
      "MAE: 1552.41\n",
      "MAE: 1553.00\n",
      "MAE: 1554.08\n",
      "MAE: 1550.40\n",
      "MAE: 1551.43\n",
      "MAE: 1551.63\n",
      "MAE: 1554.42\n",
      "MAE: 1547.40\n",
      "MAE: 1545.07\n",
      "MAE: 1544.84\n",
      "MAE: 1549.89\n",
      "MAE: 1549.67\n",
      "MAE: 1547.64\n",
      "MAE: 1549.00\n",
      "MAE: 1550.87\n",
      "MAE: 1549.71\n",
      "MAE: 1546.32\n",
      "MAE: 1546.35\n",
      "MAE: 1547.44\n",
      "MAE: 1548.01\n",
      "MAE: 1548.28\n",
      "MAE: 1548.49\n",
      "MAE: 1550.47\n",
      "MAE: 1550.75\n",
      "MAE: 1548.91\n",
      "MAE: 1549.09\n",
      "MAE: 1545.62\n",
      "MAE: 1549.66\n",
      "MAE: 1550.14\n",
      "MAE: 1550.52\n",
      "MAE: 1550.81\n",
      "MAE: 1555.05\n",
      "MAE: 1551.76\n",
      "MAE: 1554.45\n",
      "MAE: 1552.42\n",
      "MAE: 1551.09\n",
      "MAE: 1551.63\n",
      "MAE: 1551.11\n",
      "MAE: 1549.13\n",
      "MAE: 1548.28\n",
      "MAE: 1549.47\n",
      "MAE: 1550.46\n",
      "MAE: 1549.95\n",
      "MAE: 1552.89\n",
      "MAE: 1552.89\n",
      "MAE: 1551.78\n",
      "MAE: 1552.21\n",
      "MAE: 1550.75\n",
      "MAE: 1549.85\n",
      "MAE: 1550.63\n",
      "MAE: 1550.86\n",
      "MAE: 1548.68\n",
      "MAE: 1551.12\n",
      "MAE: 1550.54\n",
      "MAE: 1550.21\n",
      "MAE: 1550.11\n",
      "MAE: 1549.56\n",
      "MAE: 1551.21\n",
      "MAE: 1551.79\n",
      "MAE: 1553.70\n",
      "MAE: 1559.16\n",
      "MAE: 1561.30\n",
      "MAE: 1561.39\n",
      "MAE: 1561.21\n",
      "MAE: 1561.35\n",
      "MAE: 1560.93\n",
      "MAE: 1563.90\n",
      "MAE: 1565.07\n",
      "MAE: 1567.68\n",
      "MAE: 1569.96\n",
      "MAE: 1570.28\n",
      "MAE: 1571.61\n",
      "MAE: 1570.17\n",
      "MAE: 1571.39\n",
      "MAE: 1570.95\n",
      "MAE: 1575.27\n",
      "MAE: 1579.37\n",
      "MAE: 1578.65\n",
      "MAE: 1578.74\n",
      "MAE: 1584.20\n",
      "MAE: 1583.90\n",
      "MAE: 1583.52\n",
      "MAE: 1584.09\n",
      "MAE: 1583.39\n",
      "MAE: 1583.57\n",
      "MAE: 1583.45\n",
      "MAE: 1583.29\n",
      "MAE: 1585.20\n",
      "MAE: 1584.54\n",
      "MAE: 1584.29\n",
      "MAE: 1583.87\n",
      "MAE: 1583.86\n",
      "MAE: 1584.93\n",
      "MAE: 1584.21\n",
      "MAE: 1584.37\n",
      "MAE: 1584.84\n",
      "MAE: 1586.41\n",
      "MAE: 1584.77\n",
      "MAE: 1584.74\n",
      "MAE: 1583.45\n",
      "MAE: 1584.41\n",
      "MAE: 1582.75\n",
      "MAE: 1583.44\n",
      "MAE: 1585.20\n",
      "MAE: 1584.84\n",
      "MAE: 1585.17\n",
      "MAE: 1584.67\n",
      "MAE: 1584.06\n",
      "MAE: 1584.08\n",
      "MAE: 1584.10\n",
      "MAE: 1584.18\n",
      "MAE: 1585.02\n",
      "MAE: 1584.25\n",
      "MAE: 1584.86\n",
      "MAE: 1584.38\n",
      "MAE: 1584.33\n",
      "MAE: 1584.17\n",
      "MAE: 1584.09\n",
      "MAE: 1584.75\n",
      "MAE: 1584.13\n",
      "MAE: 1584.07\n",
      "MAE: 1583.94\n",
      "MAE: 1585.06\n",
      "MAE: 1584.89\n",
      "MAE: 1584.03\n",
      "MAE: 1584.13\n",
      "MAE: 1584.88\n",
      "MAE: 1584.14\n",
      "MAE: 1583.46\n",
      "MAE: 1583.39\n",
      "MAE: 1583.33\n",
      "MAE: 1583.18\n",
      "MAE: 1583.26\n",
      "MAE: 1583.53\n",
      "MAE: 1584.13\n",
      "MAE: 1584.66\n",
      "MAE: 1583.98\n",
      "MAE: 1584.37\n",
      "MAE: 1584.39\n",
      "MAE: 1585.20\n",
      "MAE: 1584.60\n",
      "MAE: 1584.69\n",
      "MAE: 1584.54\n",
      "MAE: 1584.81\n",
      "MAE: 1585.63\n",
      "MAE: 1584.76\n",
      "MAE: 1584.93\n",
      "MAE: 1584.55\n",
      "MAE: 1584.34\n",
      "MAE: 1584.80\n",
      "MAE: 1585.00\n",
      "MAE: 1585.80\n",
      "MAE: 1584.28\n",
      "MAE: 1584.74\n",
      "MAE: 1586.07\n",
      "MAE: 1583.94\n",
      "MAE: 1583.54\n",
      "MAE: 1584.04\n",
      "MAE: 1583.37\n",
      "MAE: 1584.04\n",
      "MAE: 1583.92\n",
      "MAE: 1584.32\n",
      "MAE: 1584.03\n",
      "MAE: 1585.92\n",
      "MAE: 1583.11\n",
      "MAE: 1584.91\n",
      "MAE: 1582.20\n",
      "MAE: 1584.29\n",
      "MAE: 1584.12\n",
      "MAE: 1584.84\n",
      "MAE: 1584.90\n",
      "MAE: 1586.18\n",
      "MAE: 1586.71\n",
      "MAE: 1584.96\n",
      "MAE: 1584.81\n",
      "MAE: 1583.40\n",
      "MAE: 1586.26\n",
      "MAE: 1585.78\n",
      "MAE: 1583.39\n",
      "MAE: 1591.63\n",
      "MAE: 1591.74\n",
      "MAE: 1591.28\n",
      "MAE: 1592.32\n",
      "MAE: 1592.36\n",
      "MAE: 1591.78\n",
      "MAE: 1595.31\n",
      "MAE: 1597.59\n",
      "MAE: 1597.27\n",
      "MAE: 1596.14\n",
      "MAE: 1596.69\n",
      "MAE: 1597.16\n",
      "MAE: 1596.86\n",
      "MAE: 1596.14\n",
      "MAE: 1596.49\n",
      "MAE: 1596.33\n",
      "MAE: 1596.33\n",
      "MAE: 1596.48\n",
      "MAE: 1597.58\n",
      "MAE: 1597.10\n",
      "MAE: 1597.05\n",
      "MAE: 1598.40\n",
      "MAE: 1597.17\n",
      "MAE: 1596.76\n",
      "MAE: 1596.52\n",
      "MAE: 1597.02\n",
      "MAE: 1596.70\n",
      "MAE: 1598.30\n",
      "MAE: 1598.14\n",
      "MAE: 1597.75\n",
      "MAE: 1597.44\n",
      "MAE: 1597.00\n",
      "MAE: 1597.57\n",
      "MAE: 1598.67\n",
      "MAE: 1595.63\n",
      "MAE: 1596.90\n",
      "MAE: 1596.05\n",
      "MAE: 1596.16\n",
      "MAE: 1596.96\n",
      "MAE: 1597.13\n",
      "MAE: 1595.86\n",
      "MAE: 1598.17\n",
      "MAE: 1597.18\n",
      "MAE: 1596.58\n",
      "MAE: 1597.02\n",
      "MAE: 1598.13\n",
      "MAE: 1597.62\n",
      "MAE: 1597.59\n",
      "MAE: 1596.68\n",
      "MAE: 1596.31\n",
      "MAE: 1596.93\n",
      "MAE: 1595.34\n",
      "MAE: 1597.48\n",
      "MAE: 1596.51\n",
      "MAE: 1596.50\n",
      "MAE: 1595.94\n",
      "MAE: 1596.24\n",
      "MAE: 1597.73\n",
      "MAE: 1596.52\n",
      "MAE: 1597.30\n",
      "MAE: 1596.77\n",
      "MAE: 1596.50\n",
      "MAE: 1596.65\n",
      "MAE: 1597.17\n",
      "MAE: 1595.79\n",
      "MAE: 1595.78\n",
      "MAE: 1596.01\n",
      "MAE: 1596.45\n",
      "MAE: 1596.43\n",
      "MAE: 1596.22\n",
      "MAE: 1597.03\n",
      "MAE: 1595.46\n",
      "MAE: 1596.17\n",
      "MAE: 1595.90\n",
      "MAE: 1597.05\n",
      "MAE: 1596.91\n",
      "MAE: 1596.38\n",
      "MAE: 1595.62\n",
      "MAE: 1596.77\n",
      "MAE: 1596.54\n",
      "MAE: 1596.97\n",
      "MAE: 1596.13\n",
      "MAE: 1596.31\n",
      "MAE: 1598.00\n",
      "MAE: 1598.26\n",
      "MAE: 1596.70\n",
      "MAE: 1598.57\n",
      "MAE: 1596.99\n",
      "MAE: 1596.14\n",
      "MAE: 1598.77\n",
      "MAE: 1596.63\n",
      "MAE: 1596.32\n",
      "MAE: 1596.30\n",
      "MAE: 1609.36\n",
      "MAE: 1614.57\n",
      "MAE: 1614.45\n",
      "MAE: 1614.91\n",
      "MAE: 1613.86\n",
      "MAE: 1614.97\n",
      "MAE: 1614.90\n",
      "MAE: 1613.93\n",
      "MAE: 1614.30\n",
      "MAE: 1615.17\n",
      "MAE: 1615.02\n",
      "MAE: 1614.78\n",
      "MAE: 1614.87\n",
      "MAE: 1614.81\n",
      "MAE: 1614.93\n",
      "MAE: 1615.49\n",
      "MAE: 1615.00\n",
      "MAE: 1614.48\n",
      "MAE: 1614.26\n",
      "MAE: 1614.89\n",
      "MAE: 1613.93\n",
      "MAE: 1614.21\n",
      "MAE: 1614.73\n",
      "MAE: 1614.77\n",
      "MAE: 1614.16\n",
      "MAE: 1614.95\n",
      "MAE: 1614.65\n",
      "MAE: 1620.59\n",
      "MAE: 1620.90\n",
      "MAE: 1620.85\n",
      "MAE: 1620.75\n",
      "MAE: 1621.44\n",
      "MAE: 1622.11\n",
      "MAE: 1621.78\n",
      "MAE: 1624.79\n",
      "MAE: 1628.12\n",
      "MAE: 1628.37\n",
      "MAE: 1629.26\n",
      "MAE: 1629.77\n",
      "MAE: 1630.09\n",
      "MAE: 1630.16\n",
      "MAE: 1630.29\n",
      "MAE: 1630.88\n",
      "MAE: 1630.10\n",
      "MAE: 1630.26\n",
      "MAE: 1630.11\n",
      "MAE: 1630.54\n",
      "MAE: 1630.61\n",
      "MAE: 1630.43\n",
      "MAE: 1630.00\n",
      "MAE: 1630.29\n",
      "MAE: 1629.99\n",
      "MAE: 1630.31\n",
      "MAE: 1629.90\n",
      "MAE: 1630.18\n",
      "MAE: 1630.00\n",
      "MAE: 1629.88\n",
      "MAE: 1629.57\n",
      "MAE: 1630.18\n",
      "MAE: 1629.91\n",
      "MAE: 1630.14\n",
      "MAE: 1630.16\n",
      "MAE: 1630.25\n",
      "MAE: 1630.17\n",
      "MAE: 1630.71\n",
      "MAE: 1630.35\n",
      "MAE: 1630.11\n",
      "MAE: 1631.47\n",
      "MAE: 1631.09\n",
      "MAE: 1630.87\n",
      "MAE: 1631.03\n",
      "MAE: 1631.22\n",
      "MAE: 1630.41\n",
      "MAE: 1630.30\n",
      "MAE: 1629.50\n",
      "MAE: 1629.98\n",
      "MAE: 1631.71\n",
      "MAE: 1629.50\n",
      "MAE: 1627.44\n",
      "MAE: 1628.66\n",
      "MAE: 1628.02\n",
      "MAE: 1629.21\n",
      "MAE: 1628.33\n",
      "MAE: 1628.56\n",
      "MAE: 1629.23\n",
      "MAE: 1628.07\n",
      "MAE: 1628.75\n",
      "MAE: 1628.29\n",
      "MAE: 1628.97\n",
      "MAE: 1628.79\n",
      "MAE: 1629.36\n",
      "MAE: 1628.03\n",
      "MAE: 1628.94\n",
      "MAE: 1627.55\n",
      "MAE: 1629.98\n",
      "MAE: 1628.44\n",
      "MAE: 1628.68\n",
      "MAE: 1628.43\n",
      "MAE: 1628.31\n",
      "MAE: 1627.96\n",
      "MAE: 1627.47\n",
      "MAE: 1628.06\n",
      "MAE: 1628.26\n",
      "MAE: 1628.53\n",
      "MAE: 1627.98\n",
      "MAE: 1629.54\n",
      "MAE: 1628.23\n",
      "MAE: 1628.02\n",
      "MAE: 1628.33\n",
      "MAE: 1628.44\n",
      "MAE: 1628.03\n",
      "MAE: 1628.14\n",
      "MAE: 1627.93\n",
      "MAE: 1628.21\n",
      "MAE: 1627.64\n",
      "MAE: 1627.74\n",
      "MAE: 1628.18\n",
      "MAE: 1628.01\n",
      "MAE: 1628.14\n",
      "MAE: 1628.30\n",
      "MAE: 1628.22\n",
      "MAE: 1628.48\n",
      "MAE: 1628.46\n",
      "MAE: 1628.81\n",
      "MAE: 1628.35\n",
      "MAE: 1628.96\n",
      "MAE: 1628.53\n",
      "MAE: 1627.80\n",
      "MAE: 1628.22\n",
      "MAE: 1628.53\n",
      "MAE: 1628.08\n",
      "MAE: 1628.26\n",
      "MAE: 1629.45\n",
      "MAE: 1629.02\n",
      "MAE: 1628.25\n",
      "MAE: 1628.69\n",
      "MAE: 1628.60\n",
      "MAE: 1628.08\n",
      "MAE: 1627.66\n",
      "MAE: 1627.70\n",
      "MAE: 1628.08\n",
      "MAE: 1628.36\n",
      "MAE: 1628.34\n",
      "MAE: 1627.87\n",
      "MAE: 1628.96\n",
      "MAE: 1627.93\n",
      "MAE: 1628.56\n",
      "MAE: 1628.67\n",
      "MAE: 1628.47\n",
      "MAE: 1627.90\n",
      "MAE: 1628.38\n",
      "MAE: 1629.02\n",
      "MAE: 1628.66\n",
      "MAE: 1627.62\n",
      "MAE: 1627.13\n",
      "MAE: 1628.25\n",
      "MAE: 1628.25\n",
      "MAE: 1628.85\n",
      "MAE: 1629.42\n",
      "MAE: 1629.45\n",
      "MAE: 1627.75\n",
      "MAE: 1628.19\n",
      "MAE: 1628.77\n",
      "MAE: 1628.49\n",
      "MAE: 1628.36\n",
      "MAE: 1628.12\n",
      "MAE: 1628.30\n",
      "MAE: 1628.10\n",
      "MAE: 1628.12\n",
      "MAE: 1628.53\n",
      "MAE: 1627.90\n",
      "MAE: 1628.13\n",
      "MAE: 1627.91\n",
      "MAE: 1628.76\n",
      "MAE: 1628.78\n",
      "MAE: 1628.31\n",
      "MAE: 1628.03\n",
      "MAE: 1629.64\n",
      "MAE: 1629.94\n",
      "MAE: 1628.40\n",
      "MAE: 1628.53\n",
      "MAE: 1628.29\n",
      "MAE: 1628.20\n",
      "MAE: 1628.40\n",
      "MAE: 1628.55\n",
      "MAE: 1628.79\n",
      "MAE: 1627.76\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[218], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m X_window \u001b[38;5;241m=\u001b[39m X_train_preproc[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m528\u001b[39m]\n\u001b[1;32m      4\u001b[0m y_window \u001b[38;5;241m=\u001b[39m y_train[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m528\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel_xgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_xgb\u001b[38;5;241m.\u001b[39mpredict(X_eval_preproc)\n\u001b[1;32m      7\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_eval, y_pred)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/forecasting_gold_price/lib/python3.10/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/forecasting_gold_price/lib/python3.10/site-packages/xgboost/sklearn.py:961\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    956\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    958\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[1;32m    959\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m    960\u001b[0m )\n\u001b[0;32m--> 961\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/forecasting_gold_price/lib/python3.10/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/forecasting_gold_price/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/forecasting_gold_price/lib/python3.10/site-packages/xgboost/core.py:1778\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1778\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model on a rolling window of data\n",
    "for i in range(len(X_train_preproc) - 528):  # Use a 30-days rolling window\n",
    "    X_window = X_train_preproc[i:i+528]\n",
    "    y_window = y_train[i:i+528]\n",
    "    model_xgb.fit(X_window, y_window)\n",
    "    y_pred = model_xgb.predict(X_eval_preproc)\n",
    "    mae = mean_absolute_error(y_eval, y_pred)\n",
    "    print(f\"MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7e70cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb2 = XGBRegressor(\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=500,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "989cd1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1650.97\n",
      "MAE: 1651.10\n",
      "MAE: 1651.04\n",
      "MAE: 1651.12\n",
      "MAE: 1651.05\n",
      "MAE: 1651.02\n",
      "MAE: 1651.08\n",
      "MAE: 1651.09\n",
      "MAE: 1651.22\n",
      "MAE: 1651.13\n",
      "MAE: 1651.03\n",
      "MAE: 1651.03\n",
      "MAE: 1651.04\n",
      "MAE: 1651.09\n",
      "MAE: 1651.07\n",
      "MAE: 1651.08\n",
      "MAE: 1651.00\n",
      "MAE: 1651.01\n",
      "MAE: 1651.28\n",
      "MAE: 1645.79\n",
      "MAE: 1644.20\n",
      "MAE: 1642.27\n",
      "MAE: 1642.48\n",
      "MAE: 1642.23\n",
      "MAE: 1642.40\n",
      "MAE: 1642.59\n",
      "MAE: 1642.35\n",
      "MAE: 1642.51\n",
      "MAE: 1642.48\n",
      "MAE: 1642.50\n",
      "MAE: 1642.45\n",
      "MAE: 1642.36\n",
      "MAE: 1642.12\n",
      "MAE: 1642.18\n",
      "MAE: 1642.24\n",
      "MAE: 1642.12\n",
      "MAE: 1642.53\n",
      "MAE: 1641.55\n",
      "MAE: 1636.69\n",
      "MAE: 1634.94\n",
      "MAE: 1635.10\n",
      "MAE: 1635.69\n",
      "MAE: 1632.09\n",
      "MAE: 1632.21\n",
      "MAE: 1631.19\n",
      "MAE: 1630.99\n",
      "MAE: 1631.21\n",
      "MAE: 1631.16\n",
      "MAE: 1631.13\n",
      "MAE: 1626.84\n",
      "MAE: 1625.69\n",
      "MAE: 1625.69\n",
      "MAE: 1625.28\n",
      "MAE: 1624.44\n",
      "MAE: 1624.41\n",
      "MAE: 1624.41\n",
      "MAE: 1624.41\n",
      "MAE: 1624.43\n",
      "MAE: 1624.49\n",
      "MAE: 1624.46\n",
      "MAE: 1624.49\n",
      "MAE: 1624.37\n",
      "MAE: 1624.44\n",
      "MAE: 1624.47\n",
      "MAE: 1624.48\n",
      "MAE: 1624.49\n",
      "MAE: 1624.49\n",
      "MAE: 1624.37\n",
      "MAE: 1624.49\n",
      "MAE: 1624.51\n",
      "MAE: 1624.53\n",
      "MAE: 1624.46\n",
      "MAE: 1624.49\n",
      "MAE: 1624.36\n",
      "MAE: 1624.45\n",
      "MAE: 1624.43\n",
      "MAE: 1624.49\n",
      "MAE: 1624.45\n",
      "MAE: 1624.48\n",
      "MAE: 1624.43\n",
      "MAE: 1624.42\n",
      "MAE: 1624.43\n",
      "MAE: 1624.41\n",
      "MAE: 1624.42\n",
      "MAE: 1624.41\n",
      "MAE: 1624.41\n",
      "MAE: 1624.40\n",
      "MAE: 1624.46\n",
      "MAE: 1624.37\n",
      "MAE: 1624.49\n",
      "MAE: 1624.40\n",
      "MAE: 1624.53\n",
      "MAE: 1624.41\n",
      "MAE: 1624.43\n",
      "MAE: 1624.37\n",
      "MAE: 1624.41\n",
      "MAE: 1624.45\n",
      "MAE: 1624.36\n",
      "MAE: 1624.37\n",
      "MAE: 1624.41\n",
      "MAE: 1625.00\n",
      "MAE: 1616.88\n",
      "MAE: 1614.84\n",
      "MAE: 1614.98\n",
      "MAE: 1615.13\n",
      "MAE: 1615.17\n",
      "MAE: 1607.44\n",
      "MAE: 1607.38\n",
      "MAE: 1607.18\n",
      "MAE: 1607.25\n",
      "MAE: 1605.44\n",
      "MAE: 1605.45\n",
      "MAE: 1603.24\n",
      "MAE: 1603.22\n",
      "MAE: 1603.43\n",
      "MAE: 1603.11\n",
      "MAE: 1603.17\n",
      "MAE: 1603.14\n",
      "MAE: 1604.07\n",
      "MAE: 1603.83\n",
      "MAE: 1603.97\n",
      "MAE: 1603.53\n",
      "MAE: 1603.62\n",
      "MAE: 1603.52\n",
      "MAE: 1603.23\n",
      "MAE: 1603.30\n",
      "MAE: 1603.39\n",
      "MAE: 1603.31\n",
      "MAE: 1603.57\n",
      "MAE: 1603.49\n",
      "MAE: 1603.83\n",
      "MAE: 1603.48\n",
      "MAE: 1603.43\n",
      "MAE: 1603.57\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[206], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m X_window \u001b[38;5;241m=\u001b[39m X_train_preproc[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m528\u001b[39m]\n\u001b[1;32m      4\u001b[0m y_window \u001b[38;5;241m=\u001b[39m y_train[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m528\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel_xgb2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_xgb2\u001b[38;5;241m.\u001b[39mpredict(X_eval_preproc)\n\u001b[1;32m      7\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_eval, y_pred)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/forecasting_gold_price/lib/python3.10/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/forecasting_gold_price/lib/python3.10/site-packages/xgboost/sklearn.py:961\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    956\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    958\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[1;32m    959\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m    960\u001b[0m )\n\u001b[0;32m--> 961\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/forecasting_gold_price/lib/python3.10/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/forecasting_gold_price/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/forecasting_gold_price/lib/python3.10/site-packages/xgboost/core.py:1778\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1778\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model on a rolling window of data. XGB2 model - specific parameters\n",
    "for i in range(len(X_train_preproc) - 528):  # Use a 30-days rolling window\n",
    "    X_window = X_train_preproc[i:i+528]\n",
    "    y_window = y_train[i:i+528]\n",
    "    model_xgb2.fit(X_window, y_window)\n",
    "    y_pred = model_xgb2.predict(X_eval_preproc)\n",
    "    mae = mean_absolute_error(y_eval, y_pred)\n",
    "    print(f\"MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2ca98fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Linear Regression): 0.17\n"
     ]
    }
   ],
   "source": [
    "# Create a linear regression model\n",
    "model_lr = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model_lr.fit(X_train_preproc, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = model_lr.predict(X_eval_preproc)\n",
    "\n",
    "# Calculate MAE\n",
    "mae_lr = mean_absolute_error(y_eval, y_pred_lr)\n",
    "print(f\"MAE (Linear Regression): {mae_lr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3bb37536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2872.356988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2877.492522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2883.259727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2887.322216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2879.229175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0  2872.356988\n",
       "1  2877.492522\n",
       "2  2883.259727\n",
       "3  2887.322216\n",
       "4  2879.229175"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred_lr).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5e80f5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18489    2872.30\n",
       "18490    2877.41\n",
       "18491    2883.25\n",
       "18492    2887.37\n",
       "18493    2879.29\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549ca33",
   "metadata": {},
   "source": [
    "##Simplest Baseline for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "831038ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (shift): 6.10\n"
     ]
    }
   ],
   "source": [
    "y_pred_baseline = y_eval.shift(1).dropna()\n",
    "y_true = y_eval[1:]\n",
    "mae_baseline = mean_absolute_error(y_true, y_pred_baseline)\n",
    "print(f\"MAE (shift): {mae_baseline:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ef03140d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(0,1,0)(0,0,0)[1] intercept   : AIC=102326.666, Time=0.11 sec\n",
      " ARIMA(1,1,0)(0,0,0)[1] intercept   : AIC=102328.050, Time=0.19 sec\n",
      " ARIMA(0,1,1)(0,0,0)[1] intercept   : AIC=102328.060, Time=0.22 sec\n",
      " ARIMA(2,1,0)(0,0,0)[1] intercept   : AIC=102328.674, Time=0.26 sec\n",
      " ARIMA(1,1,1)(0,0,0)[1] intercept   : AIC=102330.055, Time=0.31 sec\n",
      " ARIMA(0,1,2)(0,0,0)[1] intercept   : AIC=102328.747, Time=0.43 sec\n",
      " ARIMA(3,1,2)(0,0,0)[1] intercept   : AIC=102326.913, Time=1.40 sec\n",
      " ARIMA(2,1,1)(0,0,0)[1] intercept   : AIC=102322.953, Time=1.62 sec\n",
      " ARIMA(3,1,1)(0,0,0)[1] intercept   : AIC=102324.741, Time=1.80 sec\n",
      " ARIMA(2,1,3)(0,0,0)[1] intercept   : AIC=102326.856, Time=2.02 sec\n",
      "\n",
      "Best model:  ARIMA(2,1,1)(0,0,0)[1] intercept\n",
      "Total fit time: 4.362 seconds\n"
     ]
    }
   ],
   "source": [
    "# SARIMAX test\n",
    "\n",
    "import pmdarima as pm\n",
    "sarimax = pm.auto_arima(y_train, exogenous=X_train_preproc,\n",
    "                           start_p=1, start_d=1,start_q=1,\n",
    "                           test='adf',\n",
    "                           max_p=3, max_d=2, max_q=3, m=1,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           D=None, trace=True,\n",
    "                           suppress_warnings=True,\n",
    "                           stepwise=False, n_jobs=-1,\n",
    "                           random=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c7c6251c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 496.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafael.hayashi/.pyenv/versions/3.10.6/envs/forecasting_gold_price/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/Users/rafael.hayashi/.pyenv/versions/3.10.6/envs/forecasting_gold_price/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "y_pred_sar = sarimax.predict(n_periods=len(y_eval), exogenous=X_eval_preproc)\n",
    "\n",
    "# Calculate MAE\n",
    "\n",
    "mae_sarimax = mean_absolute_error(y_eval, y_pred_sar)\n",
    "\n",
    "print(f\"MAE: {mae_sarimax:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "226166f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18488    2872.557363\n",
       "18489    2872.427175\n",
       "18490    2872.649849\n",
       "18491    2872.562954\n",
       "18492    2872.748257\n",
       "18493    2872.694226\n",
       "18494    2872.850632\n",
       "18495    2872.822008\n",
       "18496    2872.956075\n",
       "18497    2872.947094\n",
       "dtype: float64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_sar.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting_gold_price",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
